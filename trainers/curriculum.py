# trainers/curriculum.py
import torch
import torch.nn as nn

class CurriculumScheduler:
    """
    ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨ (ä¼˜åŒ–ç‰ˆ)
    
    æ¨¡å‹ç»“æ„é€‚é…ç­–ç•¥ï¼š
    - Phase 1 (Epoch 1-20): åŸºç¡€ç‰¹å¾å¯¹é½
      * é‡ç‚¹ï¼šè·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹  (InfoNCE) + èº«ä»½åˆ¤åˆ« (Triplet)
      * è¾…åŠ©ï¼šæœè£…è¯­ä¹‰å¯¹é½ (ä¸ºåç»­è§£è€¦é“ºå«)
      * ç¦ç”¨ï¼šæ‰€æœ‰è§£è€¦ç›¸å…³æŸå¤±
      
    - Phase 2 (Epoch 21-50): æ¸è¿›å¼ç‰¹å¾è§£è€¦  
      * å¼•å…¥ï¼šAH-Netç©ºé—´æ­£äº¤çº¦æŸ (Spatial Orthogonal)
      * å¼•å…¥ï¼šè¯­ä¹‰å¼•å¯¼å¯¹é½ (Semantic Alignment)
      * å¼•å…¥ï¼šå¯¹æŠ—è§£è€¦ (Adversarial) - é€æ­¥å¢å¼º
      * é™ä½ï¼šTripletæƒé‡ (é¿å…ä¸è§£è€¦å†²çª)
      
    - Phase 3 (Epoch 51+): å…¨å±€ç²¾ç»†å¾®è°ƒ
      * é™ä½ï¼šæ‰€æœ‰å¯¹æŠ—æŸå¤± (ç¨³å®šæ”¶æ•›)
      * ä¿æŒï¼šç©ºé—´æ­£äº¤ + è¯­ä¹‰å¯¹é½ (ç»´æŒè§£è€¦è´¨é‡)
      * å¾®è°ƒï¼šä½å­¦ä¹ ç‡ä¼˜åŒ–ç»†èŠ‚
    """
    
    def __init__(self, total_epochs=100, logger=None):
        self.total_epochs = total_epochs
        self.logger = logger
        
        # è°ƒæ•´é˜¶æ®µè¾¹ç•Œï¼Œç»™è§£è€¦æ›´å¤šæ—¶é—´
        self.phase1_end = 20
        self.phase2_end = 50
        
        # Phase 1: åŸºç¡€å¯¹é½ (ä¿å®ˆåˆå§‹åŒ–)
        self.base_weights = {
            'info_nce': 1.0,           # è·¨æ¨¡æ€å¯¹æ¯” (åŸºå‡†)
            'id_triplet': 5.0,         # èº«ä»½ä¸‰å…ƒç»„ (é€‚ä¸­ï¼Œé¿å…è¿‡å¤§)
            'cloth_semantic': 1.0,     # æœè£…è¯­ä¹‰ (å¢å¼ºï¼Œä¸ºè§£è€¦é“ºå«)
            'spatial_orthogonal': 0.0, # ç¦ç”¨
            'semantic_alignment': 0.0, # ç¦ç”¨
            'ortho_reg': 0.0,          # ç¦ç”¨
            'adversarial_attr': 0.0,   # ç¦ç”¨
            'adversarial_domain': 0.0, # ç¦ç”¨
            'discriminator_attr': 0.0, # ç¦ç”¨
            'discriminator_domain': 0.0# ç¦ç”¨
        }
        
        if logger:
            logger.logger.info("=" * 70)
            logger.logger.info("ğŸ“š Curriculum Scheduler Initialized (Optimized)")
            logger.logger.info("=" * 70)
            logger.logger.info(f"Phase 1 (Epoch 1-{self.phase1_end}): Base Alignment (InfoNCE + Triplet + Cloth)")
            logger.logger.info(f"Phase 2 (Epoch {self.phase1_end+1}-{self.phase2_end}): Progressive Disentanglement")
            logger.logger.info(f"Phase 3 (Epoch {self.phase2_end+1}+): Fine-tuning & Stabilization")
            logger.logger.info("=" * 70)
    
    def get_current_phase(self, epoch):
        if epoch <= self.phase1_end:
            return 1
        elif epoch <= self.phase2_end:
            return 2
        else:
            return 3
    
    def get_loss_weights(self, epoch, performance_history=None):
        phase = self.get_current_phase(epoch)
        
        if phase == 1:
            # Phase 1: çº¯åŸºç¡€å¯¹é½
            weights = {
                'info_nce': 1.0,
                'id_triplet': 5.0,
                'cloth_semantic': 1.0,
                'spatial_orthogonal': 0.0,
                'semantic_alignment': 0.0,
                'ortho_reg': 0.0,
                'adversarial_attr': 0.0,
                'adversarial_domain': 0.0,
                'discriminator_attr': 0.0,
                'discriminator_domain': 0.0
            }
            
            # æ—©è¿‡æ¸¡æ£€æµ‹ï¼šRank-1 > 35% å¯æå‰è¿›å…¥ Phase 2
            if performance_history and len(performance_history) > 0:
                latest_rank1 = performance_history[-1].get('rank1', 0.0)
                if latest_rank1 > 0.35 and epoch >= 15:
                    if self.logger:
                        self.logger.logger.info(f"ğŸ¯ Early transition triggered: Rank-1={latest_rank1:.1%}")
                    return self.get_loss_weights(self.phase1_end + 1, performance_history)
                    
        elif phase == 2:
            # Phase 2: æ¸è¿›å¼è§£è€¦ (çº¿æ€§å¢åŠ è§£è€¦å¼ºåº¦)
            progress = (epoch - self.phase1_end) / (self.phase2_end - self.phase1_end)  # 0~1
            
            weights = {
                # åŸºç¡€æŸå¤± (éšè§£è€¦å¢å¼ºè€Œé€‚åº¦é™ä½)
                'info_nce': 1.0,
                'id_triplet': max(3.0, 5.0 - progress * 1.5),  # 5.0 -> 3.5
                'cloth_semantic': 1.0 + progress * 0.5,        # 1.0 -> 1.5
                
                # AH-Net ç©ºé—´è§£è€¦ (å…³é”®)
                'spatial_orthogonal': progress * 0.5,          # 0 -> 0.5
                'ortho_reg': progress * 0.3,                   # 0 -> 0.3
                
                # è¯­ä¹‰å¼•å¯¼å¯¹é½
                'semantic_alignment': progress * 0.2,          # 0 -> 0.2
                
                # å¯¹æŠ—è§£è€¦ (é€æ­¥å¢å¼ºï¼Œä½†æ§åˆ¶ä¸Šé™é¿å…ä¸ç¨³å®š)
                'adversarial_attr': min(0.5, progress * 0.6),  # 0 -> 0.5 (ä¸Šé™)
                'adversarial_domain': min(0.2, progress * 0.3),# 0 -> 0.2 (ä¸Šé™)
                'discriminator_attr': min(0.5, progress * 0.6),# 0 -> 0.5
                'discriminator_domain': min(0.2, progress * 0.3) # 0 -> 0.2
            }
            
            # åœæ»æ£€æµ‹ï¼šæ€§èƒ½åœæ»æ—¶ä¸´æ—¶é™ä½è§£è€¦å¼ºåº¦
            if performance_history and len(performance_history) >= 5:
                recent_maps = [h.get('mAP', 0.0) for h in performance_history[-5:]]
                if max(recent_maps) - min(recent_maps) < 0.005:  # 5 epoch æ— æå‡
                    if self.logger:
                        self.logger.logger.warning(f"âš ï¸ Plateau detected at epoch {epoch}, reducing disentanglement strength")
                    weights['adversarial_attr'] *= 0.5
                    weights['adversarial_domain'] *= 0.5
                    weights['spatial_orthogonal'] *= 0.7
                    
        else:
            # Phase 3: ç²¾ç»†å¾®è°ƒ (é™ä½å¯¹æŠ—ï¼Œä¿æŒè§£è€¦)
            weights = {
                'info_nce': 1.0,
                'id_triplet': 3.0,           # ç¨³å®šä½å€¼
                'cloth_semantic': 1.5,       # ä¿æŒ
                'spatial_orthogonal': 0.5,   # ä¿æŒè§£è€¦è´¨é‡
                'ortho_reg': 0.3,            # ä¿æŒ
                'semantic_alignment': 0.2,   # ä¿æŒ
                'adversarial_attr': 0.2,     # é™ä½å¯¹æŠ—å¼ºåº¦ (ç¨³å®š)
                'adversarial_domain': 0.1,   # é™ä½
                'discriminator_attr': 0.2,   # åŒæ­¥é™ä½
                'discriminator_domain': 0.1  # åŒæ­¥é™ä½
            }
        
        return weights
    
    def get_learning_rate_multiplier(self, epoch):
        # å­¦ä¹ ç‡è¡°å‡ç­–ç•¥
        phase = self.get_current_phase(epoch)
        if phase == 1:
            return 1.0      # å…¨é€Ÿ
        elif phase == 2:
            return 0.7      # ä¸­é€Ÿ (è§£è€¦é˜¶æ®µé™ä½LRæé«˜ç¨³å®šæ€§)
        else:
            return 0.3      # ä½é€Ÿå¾®è°ƒ
    
    def should_train_discriminator(self, epoch, batch_idx, total_batches):
        # åˆ¤åˆ«å™¨è®­ç»ƒé¢‘ç‡
        phase = self.get_current_phase(epoch)
        if phase == 1:
            return False
        # Phase 2-3: æ¯2ä¸ªbatchè®­ç»ƒä¸€æ¬¡åˆ¤åˆ«å™¨ (ä¸ç”Ÿæˆå™¨äº¤æ›¿)
        return batch_idx % 2 == 0
    
    def get_freeze_config(self, epoch):
        # éª¨å¹²ç½‘ç»œè§£å†»ç­–ç•¥
        phase = self.get_current_phase(epoch)
        if phase == 1:
            return {
                'clip_unfreeze_from_layer': 8,  # å†»ç»“å‰8å±‚ï¼Œä»…è®­ç»ƒæ·±å±‚
                'vim_unfreeze_from_layer': 0,   # Vimå®Œå…¨è§£å†» (ä»»åŠ¡é€‚é…)
                'freeze_bn': True               # å†»ç»“BNç»Ÿè®¡é‡
            }
        elif phase == 2:
            return {
                'clip_unfreeze_from_layer': 4,  # é€æ­¥è§£å†»CLIP
                'vim_unfreeze_from_layer': 0,
                'freeze_bn': False              # è§£å†»BN
            }
        else:
            return {
                'clip_unfreeze_from_layer': 0,  # å…¨éƒ¨è§£å†»
                'vim_unfreeze_from_layer': 0,
                'freeze_bn': False
            }
    
    def print_phase_summary(self, epoch):
        import shutil
        phase = self.get_current_phase(epoch)
        weights = self.get_loss_weights(epoch)
        lr_mult = self.get_learning_rate_multiplier(epoch)
        
        term_width = shutil.get_terminal_size((80, 20)).columns
        width = min(max(term_width, 80), 100)
        
        phase_descriptions = {
            1: "ğŸ¯ Base Alignment: Cross-modal Feature Learning",
            2: "ğŸ”¥ Progressive Disentanglement: AH-Net + Adversarial",
            3: "âœ¨ Fine-tuning: Stabilization & Refinement"
        }
        
        if self.logger:
            self.logger.logger.info(f"{'='*width}")
            self.logger.logger.info(f"Curriculum Phase {phase} | Epoch {epoch}/{self.total_epochs}")
            self.logger.logger.info(f"{'-'*width}")
            self.logger.logger.info(f"  {phase_descriptions.get(phase, 'Unknown')}")
            self.logger.logger.info(f"  LR Multiplier: {lr_mult:.2f}x")
            
            # æ˜¾ç¤ºæ´»è·ƒæŸå¤±
            active = [(k, v) for k, v in weights.items() if v > 1e-6]
            active.sort(key=lambda x: -x[1])
            self.logger.logger.info(f"  Active Losses ({len(active)}):")
            for i in range(0, len(active), 2):
                line = " | ".join([f"{k}={v:.3f}" for k, v in active[i:i+2]])
                self.logger.logger.info(f"    {line}")
            
            self.logger.logger.info(f"{'='*width}")
    
    def should_transition_phase(self, epoch, performance_history):
        # åŸºäºæ€§èƒ½çš„æ™ºèƒ½é˜¶æ®µåˆ‡æ¢
        if not performance_history or len(performance_history) == 0:
            return False
        
        phase = self.get_current_phase(epoch)
        latest_rank1 = performance_history[-1].get('rank1', 0.0)
        
        # Phase 1 -> 2: Rank-1 > 35% ä¸”è®­ç»ƒäº†è‡³å°‘15 epoch
        if phase == 1 and latest_rank1 > 0.35 and epoch >= 15:
            return True
        # Phase 2 -> 3: Rank-1 > 55% ä¸”è®­ç»ƒäº†è‡³å°‘40 epoch
        elif phase == 2 and latest_rank1 > 0.55 and epoch >= 40:
            return True
        
        return False
