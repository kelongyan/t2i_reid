# trainers/curriculum.py
import torch
import torch.nn as nn

class CurriculumScheduler:
    # ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨ï¼šé€šè¿‡åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡ã€å­¦ä¹ ç‡å’Œæ¨¡å—å†»ç»“çŠ¶æ€ï¼Œå®ç°ä»åŸºç¡€å¯¹é½åˆ°é«˜çº§è§£è€¦çš„å¹³æ»‘è®­ç»ƒ
    # Phase 1 (Epoch 1-15): åŸºç¡€ ID åˆ¤åˆ«è®­ç»ƒ
    # Phase 2 (Epoch 16-40): å¯¹æŠ—å¼ç‰¹å¾è§£è€¦
    # Phase 3 (Epoch 41+): å…¨å±€ç²¾ç»†åŒ–å¾®è°ƒ
    
    def __init__(self, total_epochs=80, logger=None):
        self.total_epochs = total_epochs
        self.logger = logger
        
        # è®­ç»ƒé˜¶æ®µç•Œé™è®¾ç½®
        self.phase1_end = 15
        self.phase2_end = 40
        
        # åˆå§‹é˜¶æ®µåŸºç¡€æƒé‡é…ç½®
        self.base_weights = {
            'info_nce': 1.0,           # è·¨æ¨¡æ€å¯¹æ¯”æŸå¤±
            'id_triplet': 2.0,         # èº«ä»½ä¸‰å…ƒç»„æŸå¤±
            'cloth_semantic': 0.1,     # æœè£…è¯­ä¹‰æŸå¤±
            'spatial_orthogonal': 0.0, # ç©ºé—´æ­£äº¤æŸå¤±ï¼ˆåˆæœŸç¦ç”¨ï¼‰
            'semantic_alignment': 0.0, # è¯­ä¹‰å¯¹é½æŸå¤±ï¼ˆåˆæœŸç¦ç”¨ï¼‰
            'ortho_reg': 0.0,          # æ­£äº¤æ­£åˆ™åŒ–é¡¹
            'adversarial_attr': 0.0,   # å±æ€§å¯¹æŠ—æŸå¤±ï¼ˆåˆæœŸç¦ç”¨ï¼‰
            'adversarial_domain': 0.0, # åŸŸå¯¹æŠ—æŸå¤±ï¼ˆåˆæœŸç¦ç”¨ï¼‰
            'discriminator_attr': 0.0, # å±æ€§åˆ¤åˆ«å™¨æŸå¤±
            'discriminator_domain': 0.0# åŸŸåˆ¤åˆ«å™¨æŸå¤±
        }
        
        if logger:
            logger.debug_logger.info("=" * 70)
            logger.debug_logger.info("ğŸ“š è¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨å·²åˆå§‹åŒ–")
            logger.debug_logger.info("=" * 70)
            logger.debug_logger.info(f"é˜¶æ®µ 1 (Epoch 1-{self.phase1_end}): åŸºç¡€ ID åˆ¤åˆ«è®­ç»ƒ")
            logger.debug_logger.info(f"é˜¶æ®µ 2 (Epoch {self.phase1_end+1}-{self.phase2_end}): å¯¹æŠ—å¼ç‰¹å¾è§£è€¦")
            logger.debug_logger.info(f"é˜¶æ®µ 3 (Epoch {self.phase2_end+1}+): å…¨å±€ç²¾ç»†åŒ–å¾®è°ƒ")
            logger.debug_logger.info("=" * 70)
    
    def get_current_phase(self, epoch):
        # æ ¹æ®å½“å‰ Epoch è·å–æ‰€å±çš„è®­ç»ƒé˜¶æ®µ
        if epoch <= self.phase1_end:
            return 1
        elif epoch <= self.phase2_end:
            return 2
        else:
            return 3
    
    def get_loss_weights(self, epoch, performance_history=None):
        # åŠ¨æ€è®¡ç®—å½“å‰ Epoch çš„å„é¡¹æŸå¤±æƒé‡ï¼Œå®ç°å¹³æ»‘è¿‡æ¸¡
        phase = self.get_current_phase(epoch)
        
        if phase == 1:
            # ç¬¬ä¸€é˜¶æ®µï¼šä¾§é‡åŸºç¡€ç‰¹å¾å¯¹é½å’Œèº«ä»½è¯†åˆ«
            weights = {
                'info_nce': 1.0,
                'id_triplet': 2.0,
                'cloth_semantic': 0.1,
                'spatial_orthogonal': 0.0,
                'semantic_alignment': 0.0,
                'ortho_reg': 0.0,
                'adversarial_attr': 0.0,
                'adversarial_domain': 0.0,
                'discriminator_attr': 0.0,
                'discriminator_domain': 0.0
            }

            # æå‰è¿‡æ¸¡æ£€æµ‹ï¼šè‹¥ Rank-1 æ€§èƒ½è¾¾æ ‡åˆ™æå‰å¼€å¯è§£è€¦
            if performance_history and len(performance_history) > 0:
                latest_rank1 = performance_history[-1].get('rank1', 0.0)
                if latest_rank1 > 0.30 and epoch >= 10:
                    if self.logger:
                        self.logger.logger.info(f"ğŸ¯ æ€§èƒ½è§¦å‘æå‰è¿‡æ¸¡: Rank-1={latest_rank1:.1%} > 30%, æå‰è¿›å…¥é˜¶æ®µ 2")
                    return self.get_loss_weights(self.phase1_end + 1, performance_history)

        elif phase == 2:
            # ç¬¬äºŒé˜¶æ®µï¼šå¼•å…¥å¯¹æŠ—è§£è€¦ï¼Œå¹¶éšè¿›åº¦çº¿æ€§å¢åŠ è§£è€¦å¼ºåº¦
            progress = (epoch - self.phase1_end) / (self.phase2_end - self.phase1_end)

            weights = {
                'info_nce': 1.0,
                'id_triplet': 2.0 - progress * 0.5,    # é™ä½ ID æŸå¤±å æ¯”
                'cloth_semantic': 0.1 + progress * 0.2, # å¢åŠ æœè£…è¯­ä¹‰å æ¯”
                'spatial_orthogonal': progress * 0.3,   # çº¿æ€§å¢åŠ ç©ºé—´æ­£äº¤çº¦æŸ
                'semantic_alignment': progress * 0.05,  # çº¿æ€§å¢åŠ è¯­ä¹‰å¯¹é½çº¦æŸ
                'ortho_reg': progress * 0.2,           # çº¿æ€§å¢åŠ  Query æ­£äº¤æ­£åˆ™åŒ–
                'adversarial_attr': progress * 0.3,    # çº¿æ€§å¢åŠ å±æ€§å¯¹æŠ—å¼ºåº¦
                'adversarial_domain': progress * 0.1,  # çº¿æ€§å¢åŠ åŸŸå¯¹æŠ—å¼ºåº¦
                'discriminator_attr': 0.5,              # å›ºå®šåˆ¤åˆ«å™¨åŸºç¡€æƒé‡
                'discriminator_domain': 0.2
            }

            # åœæ»æ£€æµ‹ï¼šè‹¥æ€§èƒ½å¢é•¿ä¹åŠ›ï¼Œåˆ™ä¸´æ—¶å›æ‹¨è§£è€¦å¼ºåº¦å¹¶åŠ å¼º ID å­¦ä¹ 
            if performance_history and len(performance_history) >= 5:
                recent_maps = [h.get('mAP', 0.0) for h in performance_history[-5:]]
                if max(recent_maps) - min(recent_maps) < 0.01:
                    if self.logger:
                        self.logger.logger.warning(f"âš ï¸ æ£€æµ‹åˆ°æ€§èƒ½å¹³å°ï¼ŒåŠ¨æ€è°ƒæ•´æƒé‡ä»¥è·³å‡ºå±€éƒ¨æœ€ä¼˜")
                    weights['id_triplet'] *= 1.2
                    weights['adversarial_attr'] *= 0.5

        else:
            # ç¬¬ä¸‰é˜¶æ®µï¼šæ‰€æœ‰æ¨¡å—å…¨é€Ÿä¼˜åŒ–ï¼Œä¿æŒè§£è€¦ä¸æ€§èƒ½çš„å¹³è¡¡
            weights = {
                'info_nce': 1.0,
                'id_triplet': 1.5,
                'cloth_semantic': 0.3,
                'spatial_orthogonal': 0.3,
                'semantic_alignment': 0.05,
                'ortho_reg': 0.2,
                'adversarial_attr': 0.2,
                'adversarial_domain': 0.05,
                'discriminator_attr': 0.3,
                'discriminator_domain': 0.1
            }
        
        return weights
    
    def get_learning_rate_multiplier(self, epoch):
        # æ ¹æ®è®­ç»ƒé˜¶æ®µåŠ¨æ€ç¼©æ”¾å…¨å±€å­¦ä¹ ç‡
        phase = self.get_current_phase(epoch)
        if phase == 1:
            return 1.0 # ç¬¬ä¸€é˜¶æ®µå…¨é€Ÿå¯¹é½
        elif phase == 2:
            return 0.5 # ç¬¬äºŒé˜¶æ®µåŠé€Ÿè§£è€¦
        else:
            return 0.3 # ç¬¬ä¸‰é˜¶æ®µä½é€Ÿå¾®è°ƒ
    
    def should_train_discriminator(self, epoch, batch_idx, total_batches):
        # åˆ¤åˆ«å™¨è®­ç»ƒé¢‘ç‡è°ƒåº¦ï¼šç¬¬ä¸€é˜¶æ®µä¸è®­ç»ƒï¼Œåç»­é˜¶æ®µæ¯ä¸¤ä¸ª batch è®­ç»ƒä¸€æ¬¡
        phase = self.get_current_phase(epoch)
        if phase == 1:
            return False
        return batch_idx % 2 == 0
    
    def get_freeze_config(self, epoch):
        # è·å–å„é˜¶æ®µçš„æ¨¡å‹å†»ç»“/è§£å†»é…ç½®
        phase = self.get_current_phase(epoch)
        if phase == 1:
            return {
                'clip_unfreeze_from_layer': 6, # ä»…è§£å†» CLIP çš„æ·±å±‚
                'vim_unfreeze_from_layer': 0,  # è§†è§‰ç¼–ç å™¨å®Œå…¨è§£å†»
                'freeze_bn': True              # å†»ç»“ BN å±‚ä»¥ç¨³å®šåˆæœŸç»Ÿè®¡é‡
            }
        else:
            return {
                'clip_unfreeze_from_layer': 0, # å…¨éƒ¨è§£å†»è¿›è¡Œè”åˆä¼˜åŒ–
                'vim_unfreeze_from_layer': 0,
                'freeze_bn': False
            }
    
    def print_phase_summary(self, epoch):
        # æ ¼å¼åŒ–è¾“å‡ºå½“å‰è®­ç»ƒé˜¶æ®µçš„è¯¦ç»†æ‘˜è¦
        import shutil
        phase = self.get_current_phase(epoch)
        weights = self.get_loss_weights(epoch)
        lr_mult = self.get_learning_rate_multiplier(epoch)
        
        term_width = shutil.get_terminal_size((80, 20)).columns
        width = min(max(term_width, 80), 100)
        
        phase_descriptions = {
            1: "éª¨å¹²ç½‘ç»œé€‚é…ä¸ç‰¹å¾å¯¹é½é˜¶æ®µ",
            2: "åŸºäºå¯¹æŠ—æ­£åˆ™åŒ–çš„ç‰¹å¾æµå½¢è§£è€¦é˜¶æ®µ",
            3: "åŒæµè¯­ä¹‰èåˆä¸å…¨å±€ç²¾ç»†å¾®è°ƒé˜¶æ®µ"
        }
        
        phase_strategies = {
            1: "å¸¦é¢„çƒ­çš„æ ‡å‡† SGD | è§£è€¦çº¦æŸï¼šå·²ç¦ç”¨",
            2: "æ¢¯åº¦åè½¬å±‚ (GRL) | å¯¹æŠ—æƒé‡çº¿æ€§å¹³æ»‘çˆ¬å‡",
            3: "å…¨æ¨¡å—è”åˆä¼˜åŒ– | èåˆæœºåˆ¶ç²¾ç»†è°ƒä¼˜"
        }
        
        if self.logger:
            self.logger.logger.info(f"{'='*width}")
            title = f"ğŸš€ è¯¾ç¨‹å­¦ä¹ è°ƒåº¦ | Epoch {epoch} | é˜¶æ®µ {phase}"
            self.logger.logger.info(f"{title}")
            self.logger.logger.info(f"{'-'*width}")
            self.logger.logger.info(f"  ğŸ“Œ é˜¶æ®µç›®æ ‡:        {phase_descriptions.get(phase, 'æœªçŸ¥é˜¶æ®µ')}")
            self.logger.logger.info(f"  âš™ï¸  ä¼˜åŒ–ç­–ç•¥:        {phase_strategies.get(phase, 'æ ‡å‡†æ¨¡å¼')}")
            self.logger.logger.info(f"  ğŸ“‰ å­¦ä¹ ç‡ç¼©æ”¾:      {lr_mult:.4f}x")
            
            active_weights = [f"{k}={v:.4g}" for k, v in weights.items() if v > 1e-6]
            self.logger.logger.info(f"  âš–ï¸  åŠ¨æ€æŸå¤±æƒé‡:")
            for i in range(0, len(active_weights), 3):
                line = " | ".join(active_weights[i:i+3])
                self.logger.logger.info(f"      [{line}]")
            
            self.logger.logger.info(f"{'='*width}")
    
    def should_transition_phase(self, epoch, performance_history):
        # é€»è¾‘åˆ¤æ–­ï¼šæ˜¯å¦åº”å½“åŸºäºå½“å‰æ€§èƒ½æŒ‡æ ‡æå‰è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
        if not performance_history or len(performance_history) == 0:
            return False
        
        phase = self.get_current_phase(epoch)
        latest_rank1 = performance_history[-1].get('rank1', 0.0)
        
        if phase == 1 and latest_rank1 > 0.30 and epoch >= 10:
            return True
        elif phase == 2 and latest_rank1 > 0.50 and epoch >= 30:
            return True
        
        return False
