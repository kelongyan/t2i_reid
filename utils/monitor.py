# src/utils/monitor.py
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional
import numpy as np
from datetime import datetime
import json
import logging
from pathlib import Path
import torch.nn.functional as F

class TrainingMonitor:
    """
    è®­ç»ƒç›‘æ§å™¨ï¼šæ—¨åœ¨ä½¿è®­ç»ƒè¿‡ç¨‹é€æ˜åŒ–
    åŠŸèƒ½ï¼š
    1. è®°å½•ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ï¼ˆå•è¡Œç´§å‡‘æ ¼å¼ï¼‰
    2. æ¢¯åº¦å¥åº·åº¦åˆ†æï¼ˆæ‘˜è¦ + å¼‚å¸¸æ£€æµ‹ï¼‰
    3. å…³é”®æ¨¡å—ï¼ˆG-S3, Fusionï¼‰å†…éƒ¨çŠ¶æ€ç›‘æ§
    4. è‡ªåŠ¨è®°å½•æŒ‡æ ‡åˆ° JSON
    """
    
    def __init__(self, dataset_name: str, log_dir: str = "log"):
        self.dataset_name = dataset_name
        self.log_dir = Path(log_dir)
        
        # === æ–°çš„ç›®å½•ç»“æ„ ===
        # log/dataset_name/ (æ—¥å¿—æ–‡ä»¶)
        # log/dataset_name/model/ (æ¨¡å‹æ–‡ä»¶)
        self.dataset_log_dir = self.log_dir / dataset_name
        self.model_dir = self.dataset_log_dir / "model"
        
        # åˆ›å»ºç›®å½•
        self.dataset_log_dir.mkdir(parents=True, exist_ok=True)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # æ–‡ä»¶è·¯å¾„
        self.log_file = self.dataset_log_dir / "log.txt"
        self.debug_log_file = self.dataset_log_dir / "debug.txt"
        self.metrics_file = self.dataset_log_dir / "metrics.json"
        
        # 1. è®¾ç½®ä¸» Logger (Console + File)
        self.logger = logging.getLogger(f"train.{dataset_name}")
        self.logger.setLevel(logging.INFO)
        self.logger.propagate = False
        self._setup_handler(self.logger, self.log_file, level=logging.INFO, console=True)

        # [New] è®¾ç½®ä»…æ–‡ä»¶ Logger (ç”¨äºåå°è®°å½• batch ä¿¡æ¯)
        self.file_logger = logging.getLogger(f"train.{dataset_name}.file_only")
        self.file_logger.setLevel(logging.INFO)
        self.file_logger.propagate = False
        self._setup_handler(self.file_logger, self.log_file, level=logging.INFO, console=False)
        
        # 2. è®¾ç½®è°ƒè¯• Logger (File Only)
        self.debug_logger = logging.getLogger(f"train.{dataset_name}.debug")
        self.debug_logger.setLevel(logging.DEBUG)
        self.debug_logger.propagate = False
        self._setup_handler(self.debug_logger, self.debug_log_file, level=logging.DEBUG, console=False)
        
        self.metrics_history = []

    def _setup_handler(self, logger, log_path, level, console=False):
        if logger.hasHandlers():
            logger.handlers.clear()
        
        # File Handler: å®Œæ•´æ ¼å¼ï¼ˆå¸¦æ—¶é—´æˆ³å’Œçº§åˆ«ï¼‰
        file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        
        # File Handler
        fh = logging.FileHandler(log_path, mode='a', encoding='utf-8')
        fh.setFormatter(file_formatter)
        fh.setLevel(level)
        logger.addHandler(fh)
        
        # Optional Console Handler: ç®€æ´æ ¼å¼ï¼ˆä»…æ¶ˆæ¯å†…å®¹ï¼‰
        if console:
            console_formatter = logging.Formatter('%(message)s')  # åªæ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
            ch = logging.StreamHandler()
            ch.setFormatter(console_formatter)
            ch.setLevel(level)
            logger.addHandler(ch)

    # --- 1. ç‰¹å¾ç»Ÿè®¡ (é€æ˜åŒ–æ•°æ®æµ) ---
    
    def log_feature_statistics(self, features: torch.Tensor, name: str):
        """è®°å½•ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯åˆ°debug.txt (ä»…æ–‡ä»¶ï¼Œä¸æ˜¾ç¤ºç»ˆç«¯)"""
        if features is None: 
            self.debug_logger.debug(f"[{name}] Feature is None, skipped")
            return
        
        t = features.detach().cpu().float()
        
        # è®¡ç®—è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        stats_str = (
            f"[{name}] shape={list(t.shape)} | "
            f"Î¼={t.mean().item():.6f} Ïƒ={t.std().item():.6f} | "
            f"min={t.min().item():.6f} max={t.max().item():.6f} | "
            f"norm={t.norm().item():.6f}"
        )
        
        # æ£€æµ‹å¼‚å¸¸å€¼
        if torch.isnan(t).any():
            nan_count = torch.isnan(t).sum().item()
            self.debug_logger.warning(f"âš ï¸  NAN DETECTED in {name}: {nan_count} values | {stats_str}")
        elif torch.isinf(t).any():
            inf_count = torch.isinf(t).sum().item()
            self.debug_logger.warning(f"âš ï¸  INF DETECTED in {name}: {inf_count} values | {stats_str}")
        else:
            self.debug_logger.debug(stats_str)

    # --- 2. æ¢¯åº¦å¥åº·åº¦ (é€æ˜åŒ–è®­ç»ƒç¨³å®šæ€§) ---

    def log_gradients(self, model, step_name: str):
        """è®°å½•æ¢¯åº¦æ‘˜è¦å’Œå¼‚å¸¸åˆ°debug.txt (ä»…æ–‡ä»¶)"""
        grads = []
        names = []
        nan_params = []
        zero_grad_params = []
        
        for n, p in model.named_parameters():
            if p.grad is not None:
                g = p.grad
                if torch.isnan(g).any():
                    nan_params.append(n)
                g_norm = g.norm().item()
                grads.append(g_norm)
                names.append(n)
                if g_norm < 1e-7:
                    zero_grad_params.append(n)
        
        if not grads: 
            self.debug_logger.debug(f"[{step_name}] No gradients found")
            return
        
        grads = np.array(grads)
        
        # è¯¦ç»†æ‘˜è¦è®°å½•
        self.debug_logger.debug(
            f"Grad Summary [{step_name}]: Count={len(grads)} | "
            f"Mean={grads.mean():.8f} Std={grads.std():.8f} | "
            f"Max={grads.max():.6f} Min={grads.min():.10f} | "
            f"Median={np.median(grads):.8f}"
        )
        
        # NaNæ£€æµ‹
        if nan_params:
            self.debug_logger.error(f"âŒ NaN Gradients in {len(nan_params)} params: {nan_params[:5]}")
        
        # å¼‚å¸¸æ£€æµ‹ - æ¢¯åº¦çˆ†ç‚¸
        exploding = [(n, g) for n, g in zip(names, grads) if g > 5.0]
        if exploding:
            self.debug_logger.warning(
                f"âš ï¸  EXPLODING Gradients detected in {len(exploding)}/{len(grads)} layers!"
            )
            for n, g in sorted(exploding, key=lambda x: x[1], reverse=True)[:5]:
                self.debug_logger.warning(f"   - {n}: norm={g:.6f}")
        
        # å¼‚å¸¸æ£€æµ‹ - æ¢¯åº¦æ¶ˆå¤±
        if zero_grad_params:
            self.debug_logger.warning(
                f"âš ï¸  VANISHING Gradients in {len(zero_grad_params)} params (norm<1e-7)"
            )
            if len(zero_grad_params) <= 10:
                for n in zero_grad_params:
                    self.debug_logger.warning(f"   - {n}")

        # Top æ´»è·ƒå±‚
        if len(grads) >= 5:
            top_idx = grads.argsort()[::-1][:5]
            self.debug_logger.debug("ğŸ”¥ Top 5 Active Layers:")
            for i in top_idx:
                self.debug_logger.debug(f"   - {names[i]}: norm={grads[i]:.6f}")

    def log_gradient_flow(self, model):
        """ä¿æŒæ¥å£å…¼å®¹ï¼Œé€»è¾‘å·²å¹¶å…¥ log_gradients"""
        pass

    # --- 3. æŸå¤±ä¸æ‰¹æ¬¡ (é€æ˜åŒ–è¿›åº¦) ---

    def log_batch_info(self, epoch: int, batch_idx: int, total_batches: int,
                       loss_meters: Dict[str, float], lr: float, print_to_console=True):
        """è®°å½•æ¯ä¸€æ‰¹æ¬¡çš„çŠ¶æ€åˆ°log.txt (æ˜¾ç¤ºç»ˆç«¯) å’Œ debug.txt (ä»…æ–‡ä»¶ï¼Œè¯¦ç»†ç‰ˆ)"""
        # ç®€è¦ç‰ˆæœ¬
        loss_str = ', '.join([f"{k}: {v:.4f}" for k, v in loss_meters.items() if 'total' not in k])
        msg = (
            f"E{epoch} [{batch_idx}/{total_batches}] LR:{lr:.2e} | "
            f"Total:{loss_meters.get('total', 0):.4f} | {loss_str}"
        )
        
        if print_to_console:
            self.logger.info(msg)
        else:
            self.file_logger.info(msg)
        
        # è¯¦ç»†ç‰ˆæœ¬ - ä»…å†™å…¥debug.txt
        self.debug_logger.debug(
            f"Batch Detail - Epoch:{epoch} Batch:{batch_idx}/{total_batches} | LR:{lr:.2e}"
        )
        for k, v in loss_meters.items():
            self.debug_logger.debug(f"  â””â”€ {k}: {v:.6f}")

    def log_loss_breakdown(self, loss_dict: Dict[str, torch.Tensor], epoch: int, batch_idx: int):
        """è®°å½•æŸå¤±å æ¯”åˆ°debug.txt (ä»…æ–‡ä»¶)"""
        total = loss_dict['total'].item() if isinstance(loss_dict['total'], torch.Tensor) else loss_dict['total']
        if total == 0: 
            self.debug_logger.debug(f"Loss Breakdown E{epoch}B{batch_idx}: Total=0, skipped")
            return
        
        parts = []
        for k, v in loss_dict.items():
            if k == 'total': continue
            val = v.item() if isinstance(v, torch.Tensor) else v
            ratio = (val / total * 100) if total > 0 else 0
            parts.append((ratio, k, val))
        
        parts.sort(key=lambda x: -x[0])
        
        # è¯¦ç»†è®°å½•æ¯ä¸ªæŸå¤±é¡¹
        self.debug_logger.debug(f"Loss Breakdown - Epoch:{epoch} Batch:{batch_idx} Total={total:.6f}")
        for ratio, k, val in parts:
            self.debug_logger.debug(f"  â””â”€ {k}: {val:.6f} ({ratio:.2f}%)")

    def log_epoch_info(self, epoch: int, total_epochs: int, metrics: Dict[str, float]):
        """ä¿å­˜æŒ‡æ ‡åˆ°å†å²è®°å½•"""
        entry = {
            'epoch': epoch,
            'timestamp': datetime.now().isoformat(),
            **metrics
        }
        self.metrics_history.append(entry)
        with open(self.metrics_file, 'w') as f:
            json.dump(self.metrics_history, f, indent=2)

    # --- 4. æ¨¡å—ç‰¹å®šçŠ¶æ€ (é€æ˜åŒ–æ¨¡å‹å†…éƒ¨) ---

    def log_gs3_module_info(self, id_feat, cloth_feat, gate_stats=None):
        """ç›‘æ§ G-S3/FSHD è§£è€¦è´¨é‡åˆ°debug.txt (ä»…æ–‡ä»¶)"""
        self.debug_logger.debug("=== Disentangle Module Internal State ===")
        self.log_feature_statistics(id_feat, "ID_Feature")
        self.log_feature_statistics(cloth_feat, "Cloth_Feature")
        
        # æ£€æŸ¥æ­£äº¤æ€§
        if id_feat is not None and cloth_feat is not None:
            id_norm = F.normalize(id_feat, dim=-1, eps=1e-8)
            cloth_norm = F.normalize(cloth_feat, dim=-1, eps=1e-8)
            
            cos_sim = (id_norm * cloth_norm).sum(dim=-1)
            abs_cos_sim = cos_sim.abs()
            
            self.debug_logger.debug(
                f"[Orthogonality] Cosine Similarity: "
                f"mean={cos_sim.mean().item():.6f} std={cos_sim.std().item():.6f} | "
                f"abs_mean={abs_cos_sim.mean().item():.6f} (target: 0.0)"
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡çš„éæ­£äº¤æƒ…å†µ
            high_sim_count = (abs_cos_sim > 0.5).sum().item()
            if high_sim_count > 0:
                self.debug_logger.warning(
                    f"âš ï¸  {high_sim_count}/{id_feat.size(0)} samples have high correlation (>0.5)"
                )
            
        # è®°å½•é—¨æ§ç»Ÿè®¡
        if isinstance(gate_stats, dict):
            self.debug_logger.debug("[Gate Statistics]")
            for k, v in gate_stats.items():
                if isinstance(v, (int, float)):
                    self.debug_logger.debug(f"  â””â”€ {k}: {v:.6f}")
                else:
                    self.debug_logger.debug(f"  â””â”€ {k}: {v}")

    def log_gate_weights(self, weights: torch.Tensor, name: str):
        """è®°å½•é—¨æ§æƒé‡åˆ†å¸ƒ"""
        if weights is None: return
        w = weights.detach().cpu().numpy()
        self.debug_logger.debug(f"[{name}] distribution: mean={w.mean():.4f}, std={w.std():.4f}, min={w.min():.4f}, max={w.max():.4f}")

    def log_fusion_info(self, fused_feat, gate_weights=None):
        self.log_feature_statistics(fused_feat, "Fused_Embeds")
        if gate_weights is not None:
            self.log_gate_weights(gate_weights, "Fusion_Gate")

    # --- 5. ç³»ç»Ÿä¸è¾…åŠ© ---

    def log_memory_usage(self):
        """è®°å½•GPUå†…å­˜ä½¿ç”¨æƒ…å†µåˆ°debug.txt (ä»…æ–‡ä»¶)"""
        if torch.cuda.is_available():
            alloc = torch.cuda.memory_allocated() / 1024**2
            reserved = torch.cuda.memory_reserved() / 1024**2
            max_alloc = torch.cuda.max_memory_allocated() / 1024**2
            free = reserved - alloc
            
            self.debug_logger.debug(
                f"[GPU Memory] Allocated:{alloc:.1f}MB | Reserved:{reserved:.1f}MB | "
                f"Free:{free:.1f}MB | Peak:{max_alloc:.1f}MB"
            )

    def log_optimizer_state(self, optimizer, epoch):
        lrs = [pg['lr'] for pg in optimizer.param_groups]
        self.debug_logger.debug(f"Optimizer LRs [Epoch {epoch}]: {lrs}")

    def log_loss_components(self, loss_dict):
        """ä»…åœ¨ Debug ä¸­è®°å½•åŸå§‹ Loss"""
        info = {k: (v.item() if isinstance(v, torch.Tensor) else v) for k, v in loss_dict.items()}
        self.debug_logger.debug(f"Raw Loss: {info}")

    def log_data_batch_info(self, batch_data, batch_idx):
        self.debug_logger.debug(f"Batch {batch_idx} data shapes: { {k: list(v.shape) for k, v in batch_data.items() if hasattr(v, 'shape')} }")

    def log_attention_weights(self, weights, name):
        self.log_feature_statistics(weights, f"Attn_{name}")

    def log_disentangle_info(self, id_feat, cloth_feat, gate=None):
        self.log_gs3_module_info(id_feat, cloth_feat, gate_stats=gate if isinstance(gate, dict) else None)

    def log_conflict_score(self, conflict_score, step_name=""):
        """
        ğŸ”¥ æ–¹æ¡ˆä¹¦ Phase 3: Conflict Score æ—¥å¿—è¿½è¸ª

        æ ¸å¿ƒæŒ‡æ ‡ï¼šè¡¡é‡ ID å’Œ Attr æ³¨æ„åŠ›å›¾çš„ç©ºé—´é‡å ç¨‹åº¦
        - conflict_score é«˜ â†’ è§£è€¦å¤±è´¥ â†’ å›¾åƒç‰¹å¾ä¸å¯ä¿¡
        - conflict_score ä½ â†’ è§£è€¦æˆåŠŸ â†’ å›¾åƒç‰¹å¾å¯ä¿¡

        Args:
            conflict_score: [B] å†²çªåˆ†æ•°
            step_name: æ­¥éª¤åç§° (ç”¨äºæ—¥å¿—åŒºåˆ†)
        """
        if conflict_score is None:
            return

        # è½¬ä¸º numpy ä¾¿äºç»Ÿè®¡
        if isinstance(conflict_score, torch.Tensor):
            scores = conflict_score.detach().cpu().numpy()
        else:
            scores = conflict_score

        # ç»Ÿè®¡ä¿¡æ¯
        mean_score = scores.mean()
        std_score = scores.std()
        min_score = scores.min()
        max_score = scores.max()

        # åˆ†æ¡£ç»Ÿè®¡
        low_conflict = (scores < 0.01).sum()   # < 1% é‡å  â†’ ä¼˜ç§€
        mid_conflict = (scores >= 0.01) & (scores < 0.05)  # 1-5% â†’ è‰¯å¥½
        high_conflict = (scores >= 0.05) & (scores < 0.1)  # 5-10% â†’ ä¸€èˆ¬
        severe_conflict = (scores >= 0.1)  # > 10% â†’ å·®

        # è®°å½•åˆ° debug.txt
        self.debug_logger.debug(
            f"[Conflict Score{step_name}] "
            f"mean={mean_score:.6f} std={std_score:.6f} | "
            f"min={min_score:.6f} max={max_score:.6f}"
        )
        self.debug_logger.debug(
            f"  Distribution: "
            f"Excellent(<1%)={low_conflict} Good(1-5%)={mid_conflict} "
            f"Fair(5-10%)={high_conflict} Poor(>10%)={severe_conflict}"
        )

        # å¼‚å¸¸æ£€æµ‹ï¼šå¦‚æœå¹³å‡å†²çªåˆ†æ•°è¿‡é«˜ï¼Œå‘å‡ºè­¦å‘Š
        if mean_score > 0.1:
            self.debug_logger.warning(
                f"âš ï¸  [Conflict Score{step_name}] Average conflict too high: {mean_score:.4f} "
                f"(Expected < 0.05). Decoupling quality is poor!"
            )
        elif mean_score < 0.02:
            self.debug_logger.info(
                f"âœ… [Conflict Score{step_name}] Excellent decoupling quality: {mean_score:.4f}"
            )

def get_monitor_for_dataset(dataset_name: str, log_dir: str = "log") -> "TrainingMonitor":
    return TrainingMonitor(dataset_name=dataset_name, log_dir=log_dir)