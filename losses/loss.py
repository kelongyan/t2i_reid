import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from utils.loss_logger import LossLogger


class HardNegativeTripletLoss(nn.Module):
    """
    ðŸ”¥ Cosine Triplet Loss with Angular Marginï¼ˆä¿®å¤ç‰ˆï¼‰

    ä¿®å¤é—®é¢˜ï¼š
    1. ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ›¿ä»£æ¬§æ°è·ç¦»ï¼ˆé€‚é…å½’ä¸€åŒ–ç‰¹å¾ï¼‰
    2. æ·»åŠ è§’åº¦marginï¼Œæ›´ç¬¦åˆReIDä»»åŠ¡
    3. ç§»é™¤temperature scalingï¼ˆå¯¹ä½™å¼¦ç›¸ä¼¼åº¦ä¸éœ€è¦ï¼‰
    4. æ”¹è¿›hard negative miningç­–ç•¥

    Args:
        margin: è§’åº¦marginï¼ˆå¼§åº¦ï¼‰ï¼Œé»˜è®¤0.3ï¼ˆçº¦17åº¦ï¼‰
        hard_mining: æ˜¯å¦ä½¿ç”¨hard mining
        hard_ratio: Hardæ ·æœ¬æ¯”ä¾‹ï¼ˆ0-1ï¼‰
    """
    def __init__(self, margin=0.3, hard_mining=True, hard_ratio=0.5):
        super().__init__()
        self.margin = margin
        self.hard_mining = hard_mining
        self.hard_ratio = hard_ratio

    def forward(self, embeds, pids):
        """
        Args:
            embeds: [B, D] L2å½’ä¸€åŒ–åŽçš„ç‰¹å¾å‘é‡
            pids: [B] èº«ä»½æ ‡ç­¾

        Returns:
            loss: Scalar tensor
        """
        if embeds is None or pids is None:
            return torch.tensor(0.0, device='cuda')

        # NaNæ£€æµ‹
        if torch.isnan(embeds).any():
            return torch.tensor(0.0, device=embeds.device)

        # ç¡®ä¿ç‰¹å¾å·²å½’ä¸€åŒ–
        embeds = F.normalize(embeds, p=2, dim=1, eps=1e-8)
        n = embeds.size(0)

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ [B, B]
        # sim[i, j] = cos(embeds[i], embeds[j])
        sim_matrix = torch.mm(embeds, embeds.t())

        # æž„å»ºmask
        mask = pids.expand(n, n).eq(pids.expand(n, n).t())

        # ä¸ºæ¯ä¸ªæ ·æœ¬æ‰¾hard positiveå’Œhard negative
        sim_ap = []  # positive similarityï¼ˆåº”è¯¥å¤§ï¼‰
        sim_an = []  # negative similarityï¼ˆåº”è¯¥å°ï¼‰

        for i in range(n):
            # æ­£æ ·æœ¬ï¼šæŽ’é™¤è‡ªå·±
            pos_mask = mask[i].clone()
            pos_mask[i] = False

            if pos_mask.sum() > 0:
                # Hard positive: é€‰æ‹©ç›¸ä¼¼åº¦æœ€å°çš„æ­£æ ·æœ¬ï¼ˆæœ€éš¾çš„æ­£æ ·æœ¬ï¼‰
                if self.hard_mining:
                    sim_ap_i = torch.min(sim_matrix[i][pos_mask])
                else:
                    sim_ap_i = sim_matrix[i][pos_mask].mean()
                sim_ap.append(sim_ap_i)
            else:
                # å¦‚æžœæ²¡æœ‰æ­£æ ·æœ¬ï¼Œä½¿ç”¨1.0ï¼ˆå®Œç¾ŽåŒ¹é…ï¼‰
                sim_ap.append(torch.tensor(1.0, device=embeds.device))

            # è´Ÿæ ·æœ¬
            neg_mask = ~mask[i]
            if neg_mask.sum() > 0:
                # Hard negative: é€‰æ‹©ç›¸ä¼¼åº¦æœ€å¤§çš„è´Ÿæ ·æœ¬ï¼ˆæœ€éš¾çš„è´Ÿæ ·æœ¬ï¼‰
                if self.hard_mining:
                    if self.hard_ratio < 1.0:
                        k = max(1, int(neg_mask.sum() * self.hard_ratio))
                        sim_an_i, _ = torch.topk(sim_matrix[i][neg_mask], k, largest=True)
                        sim_an.append(sim_an_i.mean())
                    else:
                        sim_an_i = torch.max(sim_matrix[i][neg_mask])
                        sim_an.append(sim_an_i)
                else:
                    sim_an.append(sim_matrix[i][neg_mask].mean())
            else:
                # å¦‚æžœæ²¡æœ‰è´Ÿæ ·æœ¬ï¼Œä½¿ç”¨0.0ï¼ˆå®Œå…¨ä¸åŒ¹é…ï¼‰
                sim_an.append(torch.tensor(0.0, device=embeds.device))

        sim_ap = torch.stack(sim_ap)
        sim_an = torch.stack(sim_an)

        # ðŸ”¥ Cosine Triplet Loss
        # loss = ReLU(cos(an) - cos(ap) + margin)
        # å½“ cos(an) - cos(ap) + margin > 0 æ—¶æœ‰æŸå¤±
        # ç›®æ ‡ï¼šè®© cos(ap) å°½å¯èƒ½å¤§ï¼Œcos(an) å°½å¯èƒ½å°
        loss = F.relu(sim_an - sim_ap + self.margin).mean()

        # NaNæ£€æµ‹
        if torch.isnan(loss).any() or torch.isinf(loss).any():
            return torch.tensor(0.0, device=embeds.device)

        return loss


class ReconstructionLoss(nn.Module):
    """
    AH-Net ç‰¹å¾é‡æž„æŸå¤±ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    ç›®æ ‡ï¼šåˆ©ç”¨ Attr åˆ†æ”¯ï¼ˆå’Œè¢«é˜»æ–­æ¢¯åº¦çš„ ID åˆ†æ”¯ï¼‰é‡æž„åŽŸå§‹ç‰¹å¾ï¼Œå¼ºè¿« Attr åˆ†æ”¯æ•æ‰çº¹ç†ç»†èŠ‚ã€‚
    
    æ”¹è¿›ï¼š
    1. ä½¿ç”¨ Cosine Embedding Loss æ›¿ä»£ MSEï¼Œæ›´é€‚åˆå½’ä¸€åŒ–ç‰¹å¾
    2. æ·»åŠ  L1 æ­£åˆ™åŒ–ï¼Œé¼“åŠ±ç¨€ç–é‡æž„
    """
    def __init__(self, use_cosine=True, l1_weight=0.01):
        super().__init__()
        self.use_cosine = use_cosine
        self.l1_weight = l1_weight
        self.mse_loss = nn.MSELoss()

    def forward(self, recon_feat, target_feat):
        """
        Args:
            recon_feat: [B, D] è§£ç å™¨è¾“å‡º
            target_feat: [B, D] ç›®æ ‡ç‰¹å¾ (åŽŸå§‹ç‰¹å¾å‡å€¼)
        """
        if self.use_cosine:
            # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±ï¼ˆæ›´é€‚åˆè®­ç»ƒåˆæœŸï¼‰
            recon_norm = F.normalize(recon_feat, dim=-1, eps=1e-8)
            target_norm = F.normalize(target_feat, dim=-1, eps=1e-8)
            # 1 - cosine_similarity
            cosine_loss = 1.0 - (recon_norm * target_norm).sum(dim=-1).mean()
            
            # L1 æ­£åˆ™åŒ–
            l1_reg = torch.abs(recon_feat).mean()
            
            return cosine_loss + self.l1_weight * l1_reg
        else:
            return self.mse_loss(recon_feat, target_feat)


class SpatialOrthogonalLoss(nn.Module):
    """
    ðŸ”¥ æ”¹è¿›çš„ç©ºé—´äº’æ–¥æŸå¤± (Spatial Orthogonal Loss)
    ç›®æ ‡ï¼šæœ€å°åŒ– ID Attention Map å’Œ Attr Attention Map çš„ç©ºé—´é‡å 

    æ”¹è¿›ï¼š
    1. æ·»åŠ æ¸©åº¦å‚æ•°é˜²æ­¢æ³¨æ„åŠ›é¥±å’Œ
    2. ä½¿ç”¨KLæ•£åº¦å¢žå¼ºæƒ©ç½š
    3. æ·»åŠ å½’ä¸€åŒ–é˜²æ­¢æ•°å€¼ä¸ç¨³å®š
    4. ðŸ”¥ æ·»åŠ NaNæ£€æµ‹å’Œæ•°å€¼èŒƒå›´é™åˆ¶
    5. ðŸ”¥ ä¼˜åŒ–temperatureå‚æ•°ï¼ˆä»Ž2.0æ”¹ä¸º5.0ï¼‰
    """
    def __init__(self, temperature=5.0):
        super().__init__()
        self.temperature = temperature

    def forward(self, map_id, map_attr):
        """
        Args:
            map_id: [B, 1, H, W]
            map_attr: [B, 1, H, W]
        """
        # ðŸ”¥ æ·»åŠ è¾“å…¥NaNæ£€æµ‹
        if torch.isnan(map_id).any() or torch.isnan(map_attr).any():
            return torch.tensor(0.0, device=map_id.device, requires_grad=True)
        
        # ðŸ”¥ æ”¹è¿›1: æ·»åŠ æ¸©åº¦ç¼©æ”¾ï¼Œé˜²æ­¢æ³¨æ„åŠ›å›¾è¿‡äºŽå°–é”
        map_id_temp = map_id / self.temperature
        map_attr_temp = map_attr / self.temperature
        
        # ðŸ”¥ æ·»åŠ æ•°å€¼èŒƒå›´é™åˆ¶ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        map_id_temp = torch.clamp(map_id_temp, min=-10, max=10)
        map_attr_temp = torch.clamp(map_attr_temp, min=-10, max=10)

        # é‡æ–°å½’ä¸€åŒ–
        map_id_temp_flat = map_id_temp.reshape(map_id_temp.shape[0], -1)
        map_attr_temp_flat = map_attr_temp.reshape(map_attr_temp.shape[0], -1)
        
        # ðŸ”¥ ä½¿ç”¨ç¨³å®šçš„softmaxå®žçŽ°
        map_id_temp = F.softmax(map_id_temp_flat, dim=-1)
        map_id_temp = map_id_temp.reshape_as(map_id)
        
        map_attr_temp = F.softmax(map_attr_temp_flat, dim=-1)
        map_attr_temp = map_attr_temp.reshape_as(map_attr)

        # ðŸ”¥ æ”¹è¿›2: è®¡ç®—KLæ•£åº¦ï¼ˆè¡¡é‡åˆ†å¸ƒå·®å¼‚ï¼‰
        # ä½¿ç”¨è¾ƒå°çš„epsiloné˜²æ­¢log(0)
        eps = 1e-8
        
        # ðŸ”¥ é˜²æ­¢é™¤é›¶å’Œlog(0)
        ratio = torch.clamp(map_id_temp / (map_attr_temp + eps), min=eps, max=1.0/eps)
        log_ratio = torch.log(ratio)
        
        kl_div = map_id_temp * log_ratio

        # ðŸ”¥ æ”¹è¿›3: åŒæ—¶è®¡ç®—ç›´æŽ¥é‡å ä½œä¸ºè¾…åŠ©
        overlap = map_id_temp * map_attr_temp

        # ç»„åˆæŸå¤±ï¼šKLæ•£åº¦ + ç›´æŽ¥é‡å 
        loss_kl = kl_div.sum(dim=(2, 3)).mean()
        loss_overlap = overlap.sum(dim=(2, 3)).mean()
        
        # ðŸ”¥ æ·»åŠ æœ€ç»ˆNaNæ£€æµ‹
        if torch.isnan(loss_kl).any() or torch.isnan(loss_overlap).any():
            return torch.tensor(0.0, device=map_id.device, requires_grad=True)
        
        return loss_kl + 0.5 * loss_overlap


class Loss(nn.Module):
    """
    Complete Loss Module with Curriculum Learning Support

    åŒ…å«ï¼š
    - InfoNCE (ä¸»ä»»åŠ¡)
    - Hard Negative Triplet (èº«ä»½ä¸€è‡´æ€§)
    - Cloth Semantic (å±žæ€§å¯¹é½)
    - Reconstruction (ç»“æž„é‡æž„) - å·²ç§»é™¤
    - Spatial Orthogonal (ç©ºé—´äº’æ–¥)
    - Semantic Alignment (è¯­ä¹‰å¯¹é½)
    - Adversarial Losses (å¯¹æŠ—å¼è§£è€¦)

    ðŸ”¥ ä¼˜åŒ–åŽï¼š
    1. temperatureå‚æ•°å¢žå¤§ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
    2. æ·»åŠ æŸå¤±ç¼©æ”¾ï¼Œå¹³è¡¡å„æŸå¤±å€¼èŒƒå›´
    """

    def __init__(self, temperature=0.07, weights=None, num_classes=None, logger=None,
                 semantic_guidance=None, adversarial_decoupler=None):
        """
        Args:
            temperature: å¯¹æ¯”å­¦ä¹ æ¸©åº¦å‚æ•°ï¼ˆä¿®å¤ï¼š0.2â†’0.07ï¼Œæ›´æ ‡å‡†çš„å€¼ï¼‰
            weights: æŸå¤±æƒé‡å­—å…¸
            semantic_guidance: SemanticGuidedDecoupling æ¨¡å—
            adversarial_decoupler: AdversarialDecoupler æ¨¡å—ï¼ˆæ–°å¢žï¼‰
        """
        super().__init__()
        self.temperature = temperature
        self.num_classes = num_classes
        self.logger = logger
        self.semantic_guidance = semantic_guidance
        self.adversarial_decoupler = adversarial_decoupler

        # Label Smoothing
        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=0.1)

        # === æ ¸å¿ƒæŸå¤±æ¨¡å— ===
        # ðŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ä½™å¼¦Triplet Loss
        self._hard_triplet = HardNegativeTripletLoss(
            margin=0.3,  # è§’åº¦marginï¼ˆå¼§åº¦ï¼‰
            hard_mining=True,
            hard_ratio=0.5
        )
        # ðŸ”¥ ä¼˜åŒ–temperatureå‚æ•°ï¼š2.0â†’5.0
        self._ortho_loss = SpatialOrthogonalLoss(temperature=5.0)

        # === åˆå§‹åŒ–LossLogger ===
        self.loss_logger = LossLogger(logger.debug_logger) if logger else None

        # === ä¼˜åŒ–åŽçš„æƒé‡é…ç½®ï¼ˆå°†ç”±CurriculumScheduleråŠ¨æ€æ›´æ–°ï¼‰===
        self.weights = weights if weights is not None else {
            'info_nce': 1.0,
            'id_triplet': 50.0,  # Phase 1æžå¤§æƒé‡
            'cloth_semantic': 0.001,
            'spatial_orthogonal': 0.0,
            'semantic_alignment': 0.0,
            'ortho_reg': 0.0,
            'adversarial_attr': 0.0,
            'adversarial_domain': 0.0,
            'discriminator_attr': 0.0,
            'discriminator_domain': 0.0
        }

        self.register_buffer('_dummy', torch.zeros(1))
        self._batch_counter = 0
        if logger: self.debug_logger = logger.debug_logger
    
    def update_weights(self, new_weights):
        """ç”±CurriculumScheduleråŠ¨æ€æ›´æ–°æƒé‡"""
        self.weights.update(new_weights)
        if self.logger and self._batch_counter % 500 == 0:
            self.logger.debug_logger.debug(f"[Loss] Weights updated: {new_weights}")

    def _get_device(self):
        return self._dummy.device

    def info_nce_loss(self, image_embeds, text_embeds, fused_embeds=None):
        if image_embeds is None or text_embeds is None:
            return torch.tensor(0.0, device=self._get_device())
        visual_embeds = fused_embeds if fused_embeds is not None else image_embeds
        bsz = visual_embeds.size(0)
        
        # ðŸ”¥ æ·»åŠ NaNæ£€æµ‹
        if torch.isnan(visual_embeds).any() or torch.isnan(text_embeds).any():
            return torch.tensor(0.0, device=self._get_device())
        
        visual_embeds = F.normalize(visual_embeds, dim=-1, eps=1e-8)
        text_embeds = F.normalize(text_embeds, dim=-1, eps=1e-8)
        sim = torch.matmul(visual_embeds, text_embeds.t()) / self.temperature
        
        # ðŸ”¥ é™åˆ¶ç›¸ä¼¼åº¦èŒƒå›´ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        sim = torch.clamp(sim, min=-50, max=50)
        
        labels = torch.arange(bsz, device=sim.device, dtype=torch.long)
        loss_i2t = self.ce_loss(sim, labels)
        loss_t2i = self.ce_loss(sim.t(), labels)
        
        # ðŸ”¥ æ·»åŠ æŸå¤±NaNæ£€æµ‹
        if torch.isnan(loss_i2t).any() or torch.isnan(loss_t2i).any():
            return torch.tensor(0.0, device=self._get_device())
        
        return (loss_i2t + loss_t2i) / 2

    def cloth_semantic_loss(self, cloth_image_embeds, cloth_text_embeds):
        if cloth_image_embeds is None or cloth_text_embeds is None:
            return torch.tensor(0.0, device=self._get_device())
        
        # ðŸ”¥ æ·»åŠ NaNæ£€æµ‹
        if torch.isnan(cloth_image_embeds).any() or torch.isnan(cloth_text_embeds).any():
            return torch.tensor(0.0, device=self._get_device())
        
        bsz = cloth_image_embeds.size(0)
        cloth_image_norm = F.normalize(cloth_image_embeds, dim=-1, eps=1e-8)
        cloth_text_norm = F.normalize(cloth_text_embeds, dim=-1, eps=1e-8)
        sim = torch.matmul(cloth_image_norm, cloth_text_norm.t()) / self.temperature
        
        # ðŸ”¥ é™åˆ¶ç›¸ä¼¼åº¦èŒƒå›´ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        sim = torch.clamp(sim, min=-50, max=50)
        
        labels = torch.arange(bsz, device=sim.device, dtype=torch.long)
        loss_img2t = self.ce_loss(sim, labels)
        loss_t2img = self.ce_loss(sim.t(), labels)
        
        # ðŸ”¥ æ·»åŠ æŸå¤±NaNæ£€æµ‹
        if torch.isnan(loss_img2t).any() or torch.isnan(loss_t2img).any():
            return torch.tensor(0.0, device=self._get_device())
        
        return (loss_img2t + loss_t2img) / 2

    def triplet_loss(self, embeds, pids):
        """ä½¿ç”¨Hard Negative Mining Triplet Loss"""
        return self._hard_triplet(embeds, pids)

    def forward(self, image_embeds, id_text_embeds, fused_embeds, id_logits, id_embeds,
                cloth_embeds, cloth_text_embeds, cloth_image_embeds, pids,
                is_matched=None, epoch=None, aux_info=None, training_phase='feature'):
        """
        Compute total loss with Adversarial Training Support.

        Args:
            image_embeds: å›¾åƒåµŒå…¥ [B, D]
            id_text_embeds: IDæ–‡æœ¬åµŒå…¥ [B, D]
            fused_embeds: èžåˆåµŒå…¥ [B, D]
            id_logits: åˆ†ç±»logits (å·²åºŸå¼ƒ,ä¿æŒå…¼å®¹æ€§)
            id_embeds: IDç‰¹å¾ [B, D]
            cloth_embeds: å±žæ€§ç‰¹å¾ [B, D]
            cloth_text_embeds: å±žæ€§æ–‡æœ¬åµŒå…¥ [B, D]
            cloth_image_embeds: å±žæ€§å›¾åƒåµŒå…¥ [B, D]
            pids: äººå‘˜IDæ ‡ç­¾ [B]
            is_matched: åŒ¹é…æ ‡ç­¾ [B]
            epoch: å½“å‰è®­ç»ƒepoch
            aux_info: Auxiliary info from AHNetModule
            training_phase: 'feature' or 'discriminator' (æ–°å¢ž)

        ðŸ”¥ ä¼˜åŒ–åŽï¼š
        1. æ·»åŠ æŸå¤±ç¼©æ”¾ï¼Œå¹³è¡¡å„æŸå¤±å€¼èŒƒå›´
        2. ä¼˜åŒ–æŸå¤±æƒé‡é…ç½®
        """
        losses = {}

        # === åŸºç¡€æŸå¤± ===
        # ðŸ”¥ ä¿®å¤ï¼šåŒæ—¶è®¡ç®— Unimodal Contrastive Loss (ITC) å’Œ Fused Loss
        # 1. Unimodal Alignment (è®­ç»ƒ image_mlp å’Œ text_mlpï¼Œç”¨äºŽæŽ¨ç†)
        loss_unimodal = self.info_nce_loss(image_embeds, id_text_embeds, fused_embeds=None)

        # 2. Fused Alignment (è®­ç»ƒ Fusion æ¨¡å—)
        if fused_embeds is not None:
            loss_fused = self.info_nce_loss(image_embeds, id_text_embeds, fused_embeds=fused_embeds)
            # èžåˆæŸå¤±ä½œä¸ºè¾…åŠ©ï¼Œæƒé‡è®¾ä¸º 0.5 (å¯è°ƒ)
            losses['info_nce'] = loss_unimodal + 0.5 * loss_fused
        else:
            losses['info_nce'] = loss_unimodal

        losses['cloth_semantic'] = self.cloth_semantic_loss(cloth_image_embeds, cloth_text_embeds)
        losses['id_triplet'] = self.triplet_loss(id_embeds, pids)

        # === è¯­ä¹‰å¼•å¯¼æŸå¤± ===
        if self.semantic_guidance is not None and id_embeds is not None and cloth_embeds is not None:
            losses['semantic_alignment'] = self.semantic_guidance(
                id_feat=id_embeds,
                attr_feat=cloth_embeds,
                use_cross_separation=False
            )
        else:
            losses['semantic_alignment'] = torch.tensor(0.0, device=self._get_device())

        # === AH-Net è§£è€¦æŸå¤± ===
        if aux_info:
            losses['spatial_orthogonal'] = self._ortho_loss(aux_info['map_id'], aux_info['map_attr'])

            # Queryæ­£äº¤æ€§æ­£åˆ™åŒ–
            if 'ortho_reg' in aux_info:
                losses['ortho_reg'] = aux_info['ortho_reg']
            else:
                losses['ortho_reg'] = torch.tensor(0.0, device=self._get_device())
        else:
            losses['spatial_orthogonal'] = torch.tensor(0.0, device=self._get_device())
            losses['ortho_reg'] = torch.tensor(0.0, device=self._get_device())

        # === å¯¹æŠ—å¼è§£è€¦æŸå¤±ï¼ˆæ–°å¢žï¼‰===
        if self.adversarial_decoupler is not None and id_embeds is not None and cloth_embeds is not None:
            adv_losses = self.adversarial_decoupler(
                id_feat=id_embeds,
                cloth_feat=cloth_embeds,
                training_phase=training_phase
            )
            losses.update(adv_losses)
        else:
            # å¦‚æžœæ²¡æœ‰å¯¹æŠ—æ¨¡å—ï¼Œè®¾ç½®ä¸º0
            losses['adversarial_attr'] = torch.tensor(0.0, device=self._get_device())
            losses['adversarial_domain'] = torch.tensor(0.0, device=self._get_device())
            losses['discriminator_attr'] = torch.tensor(0.0, device=self._get_device())
            losses['discriminator_domain'] = torch.tensor(0.0, device=self._get_device())

        # === ðŸ”¥ ä¿®å¤ï¼šç§»é™¤ä¸å¿…è¦çš„æŸå¤±ç¼©æ”¾ ===
        # åŽŸæ¥çš„é™¤ä»¥10æ“ä½œä¼šå¯¼è‡´æŸå¤±å€¼è¿‡å°ï¼Œå½±å“è®­ç»ƒ
        # çŽ°åœ¨é€šè¿‡æƒé‡æ¥æŽ§åˆ¶å„æŸå¤±çš„é‡è¦æ€§ï¼Œä¸å†é¢å¤–ç¼©æ”¾
        # losses['info_nce'] = losses['info_nce'] / 10.0  # å·²ç§»é™¤
        # losses['cloth_semantic'] = losses['cloth_semantic'] / 10.0  # å·²ç§»é™¤
        # losses['semantic_alignment'] = losses['semantic_alignment'] / 10.0  # å·²ç§»é™¤

        # === è®¡ç®—æ€»æŸå¤± ===
        total_loss = torch.tensor(0.0, device=self._get_device())
        for key, value in losses.items():
            if key == 'total':
                continue

            # NaNæ£€æµ‹
            if torch.isnan(value).any():
                losses[key] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)

            # æ ¹æ®è®­ç»ƒé˜¶æ®µé€‰æ‹©æ€§ç´¯åŠ æŸå¤±
            if training_phase == 'discriminator':
                # è®­ç»ƒåˆ¤åˆ«å™¨æ—¶ï¼Œåªç´¯åŠ åˆ¤åˆ«å™¨æŸå¤±
                if key.startswith('discriminator_'):
                    weight = self.weights.get(key, 0.0)
                    if weight > 0:
                        total_loss += weight * losses[key]
            else:
                # è®­ç»ƒç‰¹å¾æå–å™¨æ—¶ï¼Œç´¯åŠ æ‰€æœ‰éžåˆ¤åˆ«å™¨æŸå¤±
                if not key.startswith('discriminator_'):
                    weight = self.weights.get(key, 0.0)
                    if weight > 0:
                        total_loss += weight * losses[key]

        losses['total'] = total_loss

        # æ—¥å¿—è®°å½•
        if self.logger and self.loss_logger and self._batch_counter % 100 == 0:
            self._batch_counter += 1

        return losses