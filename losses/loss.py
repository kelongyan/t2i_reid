import torch
import torch.nn as nn
import torch.nn.functional as F


class FrequencyConsistencyLoss(nn.Module):
    """
    é¢‘åŸŸä¸€è‡´æ€§æŸå¤±
    
    ç›®æ ‡ï¼š
    - IDç‰¹å¾åº”è¯¥ä¸ä½é¢‘ç‰¹å¾å¯¹é½
    - Attrç‰¹å¾åº”è¯¥ä¸é«˜é¢‘ç‰¹å¾å¯¹é½
    
    è¿™æ˜¯FSHD-Netçš„æ ¸å¿ƒç›‘ç£ä¿¡å·
    """
    def __init__(self):
        super().__init__()
    
    def forward(self, id_feat, attr_feat, low_freq_feat, high_freq_feat):
        """
        Args:
            id_feat: IDç‰¹å¾ [B, D]
            attr_feat: Attrç‰¹å¾ [B, D]
            low_freq_feat: ä½é¢‘ç‰¹å¾ï¼ˆå…¨å±€æ± åŒ–åï¼‰ [B, D]
            high_freq_feat: é«˜é¢‘ç‰¹å¾ï¼ˆå…¨å±€æ± åŒ–åï¼‰ [B, D]
        Returns:
            loss: é¢‘åŸŸä¸€è‡´æ€§æŸå¤±
        """
        # å½’ä¸€åŒ–
        id_norm = F.normalize(id_feat, dim=-1, eps=1e-8)
        attr_norm = F.normalize(attr_feat, dim=-1, eps=1e-8)
        low_norm = F.normalize(low_freq_feat, dim=-1, eps=1e-8)
        high_norm = F.normalize(high_freq_feat, dim=-1, eps=1e-8)
        
        # IDç‰¹å¾åº”è¯¥ä¸ä½é¢‘ç‰¹å¾ç›¸ä¼¼ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦åº”æ¥è¿‘1ï¼‰
        id_low_sim = (id_norm * low_norm).sum(dim=-1)  # [B]
        loss_id_low = (1.0 - id_low_sim).mean()
        
        # Attrç‰¹å¾åº”è¯¥ä¸é«˜é¢‘ç‰¹å¾ç›¸ä¼¼
        attr_high_sim = (attr_norm * high_norm).sum(dim=-1)
        loss_attr_high = (1.0 - attr_high_sim).mean()
        
        # æ€»æŸå¤±
        return loss_id_low + loss_attr_high


class FrequencySeparationLoss(nn.Module):
    """
    é¢‘åŸŸåˆ†ç¦»æŸå¤±ï¼ˆå¯é€‰ï¼‰
    
    ç›®æ ‡ï¼š
    - IDç‰¹å¾åº”è¯¥è¿œç¦»é«˜é¢‘ç‰¹å¾
    - Attrç‰¹å¾åº”è¯¥è¿œç¦»ä½é¢‘ç‰¹å¾
    
    è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©çº¦æŸï¼Œå¢å¼ºé¢‘åŸŸåˆ†ç¦»çš„çº¯å‡€åº¦
    """
    def __init__(self):
        super().__init__()
    
    def forward(self, id_feat, attr_feat, low_freq_feat, high_freq_feat):
        """
        Args:
            id_feat, attr_feat: [B, D]
            low_freq_feat, high_freq_feat: [B, D]
        Returns:
            loss: åˆ†ç¦»æŸå¤±
        """
        id_norm = F.normalize(id_feat, dim=-1, eps=1e-8)
        attr_norm = F.normalize(attr_feat, dim=-1, eps=1e-8)
        low_norm = F.normalize(low_freq_feat, dim=-1, eps=1e-8)
        high_norm = F.normalize(high_freq_feat, dim=-1, eps=1e-8)
        
        # IDåº”è¯¥è¿œç¦»é«˜é¢‘ï¼ˆç›¸ä¼¼åº¦åº”æ¥è¿‘0ï¼‰
        id_high_sim = torch.abs((id_norm * high_norm).sum(dim=-1))
        
        # Attråº”è¯¥è¿œç¦»ä½é¢‘
        attr_low_sim = torch.abs((attr_norm * low_norm).sum(dim=-1))
        
        # æƒ©ç½šç›¸ä¼¼åº¦ï¼ˆè¶Šæ¥è¿‘0è¶Šå¥½ï¼‰
        return id_high_sim.mean() + attr_low_sim.mean()


class SymmetricReconstructionLoss(nn.Module):
    """
    å¯¹ç§°é‡æ„æŸå¤± (Symmetric Reconstruction Loss) - å¢å¼ºç‰ˆ
    
    æ ¸å¿ƒæ€æƒ³ï¼šF_input â‰ˆ F_id + F_attr
    ç¡®ä¿è§£è€¦åçš„ä¸¤ä¸ªç‰¹å¾èƒ½å¤Ÿé‡å»ºåŸå§‹è¾“å…¥ï¼Œé˜²æ­¢ä¿¡æ¯ä¸¢å¤±
    
    ä¼˜åŒ–ï¼š
    1. ä¿ç•™MSEå’ŒCosineæŸå¤±ï¼ˆåŸºç¡€ï¼‰
    2. ã€æ–°å¢ã€‘ç‰¹å¾å¤šæ ·æ€§æŸå¤± - ç¡®ä¿idå’Œattrè¦†ç›–ä¸åŒè¯­ä¹‰ç©ºé—´
    3. ã€æ–°å¢ã€‘èƒ½é‡å®ˆæ’çº¦æŸ - ç¡®ä¿ä¿¡æ¯é‡å®ˆæ’
    """
    def __init__(self):
        super().__init__()
        self.mse_loss = nn.MSELoss()
        self.cosine_loss = nn.CosineEmbeddingLoss()
    
    def forward(self, id_feat, attr_feat, original_feat):
        """
        Args:
            id_feat: IDç‰¹å¾ [B, dim]
            attr_feat: Attrç‰¹å¾ [B, dim]
            original_feat: åŸå§‹ç‰¹å¾ï¼ˆè§£è€¦å‰çš„å…¨å±€ç‰¹å¾ï¼‰[B, dim]
            
        Returns:
            loss: é‡æ„æŸå¤±
        """
        # ç®€å•åŠ æ³•é‡å»º
        reconstructed = id_feat + attr_feat  # [B, dim]
        
        # === åŸºç¡€é‡æ„æŸå¤± ===
        # æ–¹æ¡ˆ1ï¼šMSE Lossï¼ˆL2è·ç¦»ï¼‰
        mse_loss = self.mse_loss(reconstructed, original_feat)
        
        # æ–¹æ¡ˆ2ï¼šCosine Similarity Lossï¼ˆæ–¹å‘ä¸€è‡´æ€§ï¼‰
        # CosineEmbeddingLosséœ€è¦targetä¸º1ï¼ˆè¡¨ç¤ºç›¸ä¼¼ï¼‰
        target = torch.ones(id_feat.size(0), device=id_feat.device)
        cos_loss = self.cosine_loss(
            F.normalize(reconstructed, dim=-1),
            F.normalize(original_feat, dim=-1),
            target
        )
        
        # === ã€æ–°å¢ã€‘ç‰¹å¾å¤šæ ·æ€§æŸå¤± ===
        # ç¡®ä¿idå’Œattrç‰¹å¾è¦†ç›–ä¸åŒçš„è¯­ä¹‰ç©ºé—´ï¼Œé¿å…é‡å 
        id_norm = F.normalize(id_feat, dim=-1, eps=1e-8)
        attr_norm = F.normalize(attr_feat, dim=-1, eps=1e-8)
        # è®¡ç®—idå’Œattrçš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œåº”è¯¥æ¥è¿‘0ï¼ˆæ­£äº¤ï¼‰
        diversity_loss = torch.abs((id_norm * attr_norm).sum(dim=-1)).mean()
        
        # === ã€æ–°å¢ã€‘èƒ½é‡å®ˆæ’çº¦æŸ ===
        # é‡æ„ç‰¹å¾çš„èƒ½é‡ï¼ˆL2èŒƒæ•°ï¼‰åº”æ¥è¿‘åŸå§‹ç‰¹å¾
        recon_energy = torch.norm(reconstructed, p=2, dim=-1)  # [B]
        orig_energy = torch.norm(original_feat, p=2, dim=-1)   # [B]
        energy_loss = F.mse_loss(recon_energy, orig_energy)
        
        # ç»„åˆæ‰€æœ‰æŸå¤±
        # åŸºç¡€é‡æ„(mse+cos) + å¤šæ ·æ€§ + èƒ½é‡å®ˆæ’
        total_loss = mse_loss + 0.5 * cos_loss + 0.5 * diversity_loss + 0.3 * energy_loss
        
        return total_loss


class EnhancedOrthogonalLoss(nn.Module):
    """
    å¢å¼ºæ­£äº¤æŸå¤± (Enhanced Orthogonal Loss)
    
    æ”¹è¿›ï¼šå¢åŠ äº¤å‰æ‰¹æ¬¡çº¦æŸï¼Œè®©ä¸åŒæ ·æœ¬çš„IDå’ŒAttrç‰¹å¾ç©ºé—´ä¹Ÿè¶‹å‘æ­£äº¤
    """
    def __init__(self):
        super().__init__()
    
    def forward(self, id_embeds, attr_embeds, cross_batch=True):
        """
        Args:
            id_embeds: IDç‰¹å¾ [B, dim]
            attr_embeds: Attrç‰¹å¾ [B, dim]
            cross_batch: æ˜¯å¦å¯ç”¨äº¤å‰æ‰¹æ¬¡æ­£äº¤çº¦æŸ
            
        Returns:
            loss: æ­£äº¤æŸå¤±
        """
        # å½’ä¸€åŒ–
        id_norm = F.normalize(id_embeds, dim=-1, eps=1e-8)     # [B, dim]
        attr_norm = F.normalize(attr_embeds, dim=-1, eps=1e-8) # [B, dim]
        
        # === æ‰¹æ¬¡å†…æ­£äº¤çº¦æŸï¼ˆæ ·æœ¬è‡ªå·±çš„IDå’ŒAttræ­£äº¤ï¼‰===
        # ä½™å¼¦ç›¸ä¼¼åº¦ï¼šåº”è¯¥æ¥è¿‘0
        intra_cosine = (id_norm * attr_norm).sum(dim=-1)  # [B]
        intra_cosine = torch.clamp(intra_cosine, min=-1.0, max=1.0)
        intra_loss = intra_cosine.pow(2).mean()
        
        # === äº¤å‰æ‰¹æ¬¡æ­£äº¤çº¦æŸï¼ˆæ‰€æœ‰ID vs æ‰€æœ‰Attrï¼‰===
        if cross_batch and id_embeds.size(0) > 1:
            # è®¡ç®—å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µ [B, B]
            cross_sim = torch.matmul(id_norm, attr_norm.t())
            # æœ€å°åŒ–æ‰€æœ‰å…ƒç´ çš„å¹³æ–¹å’Œï¼ˆè®©æ•´ä¸ªçŸ©é˜µè¶‹å‘0ï¼‰
            cross_loss = cross_sim.pow(2).mean()
            
            return intra_loss + 0.5 * cross_loss
        else:
            return intra_loss


class Loss(nn.Module):
    """
    === FSHDæŸå¤±å‡½æ•°æ¨¡å— (Frequency-Spatial Hybrid Decoupling Loss System) ===
    
    æ ¸å¿ƒæŸå¤±ï¼š
    - InfoNCE: ä¸»å¯¹æ¯”å­¦ä¹ æŸå¤±
    - SymmetricReconstructionLoss: ç‰¹å¾é‡æ„
    - EnhancedOrthogonalLoss: æ­£äº¤çº¦æŸ
    - FrequencyConsistencyLoss: é¢‘åŸŸä¸€è‡´æ€§ (FSHDæ ¸å¿ƒ)
    - FrequencySeparationLoss: é¢‘åŸŸåˆ†ç¦» (FSHDè¾…åŠ©)
    
    åŠ¨æ€æƒé‡è°ƒæ•´ï¼š3-stageç­–ç•¥
    """
    def __init__(self, temperature=0.1, weights=None, num_classes=None, logger=None):
        super().__init__()
        self.temperature = temperature
        self.num_classes = num_classes
        self.logger = logger
        
        # ä½¿ç”¨Label Smoothingé™ä½åˆ†ç±»æŸå¤±çš„åˆå§‹å€¼
        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=0.1)
        
        # === æ ¸å¿ƒæŸå¤±æ¨¡å— ===
        self.symmetric_reconstruction = SymmetricReconstructionLoss()
        self.enhanced_orthogonal = EnhancedOrthogonalLoss()
        
        # === FSHDé¢‘åŸŸæŸå¤± ===
        self.frequency_consistency = FrequencyConsistencyLoss()
        self.frequency_separation = FrequencySeparationLoss()
        
        # === FSHDæƒé‡é…ç½®ï¼ˆä¼˜åŒ–ç‰ˆ - å¹³è¡¡æƒé‡ï¼‰===
        # é˜¶æ®µ1ï¼šç¦ç”¨é¢‘åŸŸæŸå¤±å’Œè¯­ä¹‰å¯¹é½æŸå¤±ï¼Œæå‡è¾…åŠ©æŸå¤±æƒé‡
        self.weights = weights if weights is not None else {
            'info_nce': 1.2,              # å¯¹æ¯”å­¦ä¹  - ä¸»å¯¼
            'cls': 0.05,                  # åˆ†ç±»æŸå¤±ï¼ˆæå‡2.5å€ï¼‰
            'cloth_semantic': 1.0,        # è¡£æœè¯­ä¹‰ï¼ˆé™ä½ï¼Œé¿å…è¿‡åº¦ä¸»å¯¼ï¼‰
            'orthogonal': 0.12,           # æ­£äº¤çº¦æŸï¼ˆæå‡50%ï¼‰
            'id_triplet': 0.8,            # IDä¸€è‡´æ€§ï¼ˆæå‡60%ï¼‰
            'anti_collapse': 2.0,         # é˜²åç¼©ï¼ˆå¤§å¹…æå‡ï¼Œä¿®å¤åæ¿€æ´»ï¼‰
            'gate_adaptive': 0.05,        # é—¨æ§è‡ªé€‚åº”ï¼ˆæå‡5å€ï¼‰
            'reconstruction': 1.5,        # å¯¹ç§°é‡æ„ï¼ˆå¤§å¹…æå‡ï¼Œå¢å¼ºç‰ˆï¼‰
            'semantic_alignment': 0.0,    # ã€é˜¶æ®µ1ï¼šå®Œå…¨ç¦ç”¨ã€‘
            'freq_consistency': 0.0,      # ã€é˜¶æ®µ1ï¼šå®Œå…¨ç¦ç”¨ã€‘
            'freq_separation': 0.0,       # ã€é˜¶æ®µ1ï¼šå®Œå…¨ç¦ç”¨ã€‘
        }
        
        # åŠ¨æ€æƒé‡è°ƒæ•´å‚æ•°
        self.current_epoch = 0
        self.enable_dynamic_weights = True
        
        # è¯­ä¹‰å¼•å¯¼æ¨¡å—ï¼ˆå¤–éƒ¨ä¼ å…¥ï¼Œå¯é€‰ï¼‰
        self.semantic_guidance_module = None
        
        # æ³¨å†Œdummyå‚æ•°ç”¨äºè·å–è®¾å¤‡
        self.register_buffer('_dummy', torch.zeros(1))
        
        # è°ƒè¯•è®¡æ•°å™¨
        if logger:
            self.debug_logger = logger.debug_logger
            self._log_counter_ortho = 0
            self._log_counter_gate = 0
    
    def set_semantic_guidance(self, semantic_guidance_module):
        """
        è®¾ç½®è¯­ä¹‰å¼•å¯¼æ¨¡å—
        
        Args:
            semantic_guidance_module: SemanticGuidedDecouplingå®ä¾‹
        """
        self.semantic_guidance_module = semantic_guidance_module
        if self.logger:
            self.logger.debug_logger.info("âœ… Semantic guidance module attached to Loss")
    
    def _get_device(self):
        """å®‰å…¨è·å–è®¾å¤‡"""
        return self._dummy.device
    
    def update_epoch(self, epoch):
        """
        === åŠ¨æ€æƒé‡è°ƒæ•´ï¼ˆä¼˜åŒ–ç‰ˆ - 3-Stageç­–ç•¥ï¼‰===
        
        é˜¶æ®µ1 (Epoch 1-20): ä¼˜åŒ–åŸºç¡€è®­ç»ƒ
            - å®Œå…¨ç¦ç”¨é¢‘åŸŸæŸå¤±å’Œè¯­ä¹‰å¯¹é½
            - æå‡è¾…åŠ©æŸå¤±æƒé‡ï¼Œå¢å¼ºç›‘ç£ä¿¡å·
        
        é˜¶æ®µ2 (Epoch 21-50): æ¸è¿›æ¿€æ´»æœŸ
            - é€æ­¥å¼•å…¥é¢‘åŸŸç›‘ç£
            - å¯ç”¨è½»é‡è¯­ä¹‰å¯¹é½
        
        é˜¶æ®µ3 (Epoch 51+): å…¨é¢ä¼˜åŒ–æœŸ
            - å®Œæ•´é¢‘åŸŸæŸå¤±
            - å®Œæ•´è¯­ä¹‰å¯¹é½
        """
        self.current_epoch = epoch
        
        if not self.enable_dynamic_weights:
            return
        
        # === é˜¶æ®µ1 (Epoch 1-20): ä¼˜åŒ–åŸºç¡€è®­ç»ƒ ===
        if epoch <= 20:
            self.weights['info_nce'] = 1.2
            self.weights['cls'] = 0.05              # æå‡ï¼ˆ0.02â†’0.05ï¼‰
            self.weights['cloth_semantic'] = 1.0
            self.weights['orthogonal'] = 0.12       # æå‡ï¼ˆ0.08â†’0.12ï¼‰
            self.weights['reconstruction'] = 1.5    # å¤§å¹…æå‡ï¼ˆ0.8â†’1.5ï¼‰
            self.weights['anti_collapse'] = 2.0     # å¤§å¹…æå‡ï¼ˆ1.5â†’2.0ï¼‰
            self.weights['id_triplet'] = 0.8        # æå‡ï¼ˆ0.5â†’0.8ï¼‰
            self.weights['gate_adaptive'] = 0.05    # å¤§å¹…æå‡ï¼ˆ0.01â†’0.05ï¼‰
            # ã€å…³é”®ã€‘å®Œå…¨ç¦ç”¨
            self.weights['semantic_alignment'] = 0.0
            self.weights['freq_consistency'] = 0.0
            self.weights['freq_separation'] = 0.0
            
        # === é˜¶æ®µ2 (Epoch 21-50): æ¸è¿›æ¿€æ´» ===
        elif epoch <= 50:
            self.weights['info_nce'] = 1.0
            self.weights['cls'] = 0.08              # æŒç»­æå‡
            self.weights['cloth_semantic'] = 1.0
            self.weights['orthogonal'] = 0.12
            self.weights['reconstruction'] = 1.2
            self.weights['anti_collapse'] = 1.8
            self.weights['id_triplet'] = 0.8
            self.weights['gate_adaptive'] = 0.05
            # ã€æ¸è¿›æ¿€æ´»ã€‘
            self.weights['semantic_alignment'] = 0.05   # è½»é‡å¯ç”¨
            self.weights['freq_consistency'] = 0.3      # è½»é‡å¯ç”¨
            self.weights['freq_separation'] = 0.1
            
        # === é˜¶æ®µ3 (Epoch 51+): å…¨é¢ä¼˜åŒ– ===
        else:
            self.weights['info_nce'] = 1.0
            self.weights['cls'] = 0.1               # è¿›ä¸€æ­¥æå‡
            self.weights['cloth_semantic'] = 1.0
            self.weights['orthogonal'] = 0.12
            self.weights['reconstruction'] = 1.0
            self.weights['anti_collapse'] = 1.5
            self.weights['id_triplet'] = 0.8
            self.weights['gate_adaptive'] = 0.05
            # ã€å®Œæ•´æ¿€æ´»ã€‘
            self.weights['semantic_alignment'] = 0.08
            self.weights['freq_consistency'] = 0.5
            self.weights['freq_separation'] = 0.2
            
        # è®°å½•æƒé‡å˜åŒ–
        if self.logger and epoch in [1, 21, 51]:
            self.debug_logger.info(f"ğŸ“Š Loss weights updated at epoch {epoch}:")
            for k, v in self.weights.items():
                if v > 0:  # åªæ˜¾ç¤ºæ¿€æ´»çš„æŸå¤±
                    self.debug_logger.info(f"   - {k}: {v:.4f}")
    
    def gate_adaptive_loss_v2(self, gate_stats, id_embeds, cloth_embeds, pids):
        """
        === é—¨æ§è‡ªé€‚åº”æŸå¤±ï¼ˆå¢å¼ºç‰ˆ - æ·»åŠ ç±»é—´åˆ†ç¦»ï¼‰===
        
        ä¼˜åŒ–ï¼š
        1. ä¿ç•™ç±»å†…ç´§å‡‘ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        2. ã€æ–°å¢ã€‘ç±»é—´åˆ†ç¦»æŸå¤±ï¼ˆè§£å†³ç±»å†…ç›¸ä¼¼åº¦é¥±å’Œé—®é¢˜ï¼‰
        3. å¹³è¡¡ç±»å†…èšåˆä¸ç±»é—´åŒºåˆ†
        
        ç›®æ ‡ï¼š
        - compact_loss: ä½¿åŒç±»æ ·æœ¬çš„IDç‰¹å¾æ›´ç›¸ä¼¼
        - separation_loss: ä½¿å¼‚ç±»æ ·æœ¬çš„IDç‰¹å¾æ›´ä¸åŒ
        """
        if gate_stats is None or id_embeds is None:
            return torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        batch_size = id_embeds.size(0)
        
        # å°batchè·³è¿‡å¤æ‚è®¡ç®—
        if batch_size <= 1 or pids is None:
            return torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        # åŒç±»æ ·æœ¬mask
        mask = (pids.unsqueeze(0) == pids.unsqueeze(1)).float()
        mask = mask - torch.eye(batch_size, device=mask.device)
        
        # å¦‚æœæ²¡æœ‰åŒç±»æ ·æœ¬ï¼Œè·³è¿‡
        if mask.sum() < 1e-6:
            return torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        # å½’ä¸€åŒ–ç‰¹å¾
        id_norm = F.normalize(id_embeds, dim=-1, eps=1e-8)
        id_sim = torch.matmul(id_norm, id_norm.t())
        
        # === ç±»å†…ç´§å‡‘åº¦ï¼ˆåŸæœ‰é€»è¾‘ï¼‰===
        intra_class_sim = (id_sim * mask).sum() / (mask.sum() + 1e-8)
        compact_loss = 1.0 - intra_class_sim
        
        # === ã€æ–°å¢ã€‘ç±»é—´åˆ†ç¦»æŸå¤± ===
        # å¼‚ç±»æ ·æœ¬maskï¼ˆæ’é™¤åŒç±»å’Œå¯¹è§’çº¿ï¼‰
        neg_mask = 1.0 - mask - torch.eye(batch_size, device=mask.device)
        
        separation_loss = 0.0
        if neg_mask.sum() > 1e-6:
            # è®¡ç®—å¼‚ç±»æ ·æœ¬é—´çš„å¹³å‡ç›¸ä¼¼åº¦
            inter_class_sim = (id_sim * neg_mask).sum() / (neg_mask.sum() + 1e-8)
            # æƒ©ç½šå¼‚ç±»æ ·æœ¬ç›¸ä¼¼åº¦è¿‡é«˜
            separation_loss = torch.clamp(inter_class_sim, min=0.0)
        
        # é—¨æ§æ­£åˆ™ï¼ˆé˜²æ­¢æç«¯å€¼ï¼‰
        gate_id_mean = gate_stats.get('gate_id_mean', 0.5)
        gate_regularization = 0.0
        if gate_id_mean < 0.25 or gate_id_mean > 0.85:
            gate_regularization = 0.05 * ((gate_id_mean - 0.55) ** 2)
        
        # ç»„åˆæŸå¤±ï¼šç±»å†…ç´§å‡‘ + ç±»é—´åˆ†ç¦» + é—¨æ§æ­£åˆ™
        total_loss = compact_loss + 0.5 * separation_loss + gate_regularization
        
        # å®šæœŸè®°å½•è°ƒè¯•ä¿¡æ¯
        if self.logger:
            self._log_counter_gate = getattr(self, '_log_counter_gate', 0) + 1
            if self._log_counter_gate % 500 == 0:
                self.debug_logger.debug(
                    f"[Gate Adaptive] intra_sim={intra_class_sim:.4f} | "
                    f"inter_sim={inter_class_sim if isinstance(separation_loss, torch.Tensor) else 0:.4f} | "
                    f"compact_loss={compact_loss:.6f} | sep_loss={separation_loss if isinstance(separation_loss, torch.Tensor) else 0:.6f} | "
                    f"gate_mean={gate_id_mean:.4f}"
                )
        
        return torch.clamp(total_loss, min=0.0, max=5.0)
    
    def info_nce_loss(self, image_embeds, text_embeds, fused_embeds=None):
        """
        InfoNCEå¯¹æ¯”å­¦ä¹ æŸå¤±
        
        ä¿®å¤ï¼šæ”¯æŒä½¿ç”¨fused_embedså‚ä¸å¯¹æ¯”å­¦ä¹ 
        è®©Fusionæ¨¡å—çœŸæ­£å½±å“ä¸»ä»»åŠ¡ï¼Œé¿å…æ¢¯åº¦æ­»äº¡
        """
        if image_embeds is None or text_embeds is None:
            return torch.tensor(0.0, device=self._get_device())
        
        # ä¼˜å…ˆä½¿ç”¨fused_embedsï¼ˆèåˆåçš„ç‰¹å¾ï¼‰
        # å¦‚æœæ²¡æœ‰fusionæˆ–fusionæœªæ¿€æ´»ï¼Œåˆ™ä½¿ç”¨image_embeds
        visual_embeds = fused_embeds if fused_embeds is not None else image_embeds
        
        bsz = visual_embeds.size(0)
        visual_embeds = F.normalize(visual_embeds, dim=-1, eps=1e-8)
        text_embeds = F.normalize(text_embeds, dim=-1, eps=1e-8)
        
        sim = torch.matmul(visual_embeds, text_embeds.t()) / self.temperature
        sim = torch.clamp(sim, min=-50, max=50)
        
        labels = torch.arange(bsz, device=sim.device, dtype=torch.long)
        loss_i2t = self.ce_loss(sim, labels)
        loss_t2i = self.ce_loss(sim.t(), labels)
        
        return (loss_i2t + loss_t2i) / 2
    
    def id_classification_loss(self, id_logits, pids):
        """
        èº«ä»½åˆ†ç±»æŸå¤±
        
        === ä¿®å¤æ–¹æ¡ˆ ===
        1. ç§»é™¤æ¸©åº¦ç¼©æ”¾ - è®©åˆ†ç±»å™¨æ­£å¸¸å­¦ä¹ 
        2. ä¿ç•™logitsè£å‰ªé˜²æ­¢æ•°å€¼çˆ†ç‚¸
        3. é€šè¿‡åŠ¨æ€æƒé‡æ§åˆ¶å­¦ä¹ é€Ÿåº¦ï¼Œè€Œéæ¸©åº¦ç¼©æ”¾
        """
        if id_logits is None or pids is None:
            return torch.tensor(0.0, device=self._get_device())
        
        # è£å‰ªé˜²æ­¢æ•°å€¼çˆ†ç‚¸
        id_logits_clipped = torch.clamp(id_logits, min=-50, max=50)
        
        # ç›´æ¥è®¡ç®—CEæŸå¤±ï¼Œä¸ä½¿ç”¨æ¸©åº¦ç¼©æ”¾
        # åŸå› ï¼šæ¸©åº¦ç¼©æ”¾ä¼šä¸¥é‡æŠ‘åˆ¶å­¦ä¹ é€Ÿåº¦
        # é€šè¿‡è°ƒæ•´lossæƒé‡ï¼ˆ0.08â†’0.3ï¼‰æ¥æ§åˆ¶å­¦ä¹ è¿›åº¦æ›´åˆç†
        ce_loss = self.ce_loss(id_logits_clipped, pids)
        
        return ce_loss
    
    def cloth_semantic_loss_v2(self, cloth_image_embeds, cloth_text_embeds, id_embeds_768=None):
        """
        === ä¿®å¤æ–¹æ¡ˆï¼šç®€åŒ–çš„cloth_semanticæŸå¤± ===
        ç§»é™¤å»IDæ­£åˆ™ï¼Œè®©G-S3æ¨¡å—ä¸“æ³¨äºè§£è€¦ä»»åŠ¡
        åŸå› ï¼š
        1. å¢åŠ é¢å¤–æŠ•å½±å±‚ä¼šå¢åŠ è®­ç»ƒéš¾åº¦
        2. å»IDæƒ©ç½šä¸orthogonal_lossåŠŸèƒ½é‡å¤
        3. å®éªŒæ˜¾ç¤ºcloth_semanticå æ€»æŸå¤±83-95%ï¼Œè¯´æ˜åŸºç¡€æŸå¤±å°±å·²ç»å¾ˆé«˜
        """
        if cloth_image_embeds is None or cloth_text_embeds is None:
            return torch.tensor(0.0, device=self._get_device())
        
        bsz = cloth_image_embeds.size(0)
        
        # === æ ‡å‡†å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆä¸InfoNCEä¸€è‡´ï¼‰=== 
        cloth_image_norm = F.normalize(cloth_image_embeds, dim=-1, eps=1e-8)
        cloth_text_norm = F.normalize(cloth_text_embeds, dim=-1, eps=1e-8)
        
        sim = torch.matmul(cloth_image_norm, cloth_text_norm.t()) / self.temperature
        sim = torch.clamp(sim, min=-50, max=50)
        
        labels = torch.arange(bsz, device=sim.device, dtype=torch.long)
        loss_i2t = self.ce_loss(sim, labels)
        loss_t2i = self.ce_loss(sim.t(), labels)
        
        # ä¸å†æ·»åŠ å»IDæ­£åˆ™ï¼Œè®©æŸå¤±ä¿æŒç®€æ´
        # orthogonal_lossä¼šè´Ÿè´£èº«ä»½-æœè£…çš„è§£è€¦
        return (loss_i2t + loss_t2i) / 2
    
    def orthogonal_loss_v2(self, id_embeds, cloth_embeds):
        """
        === å¯¹ç§°è§£è€¦æ”¹è¿›ï¼šä½¿ç”¨å¢å¼ºæ­£äº¤æŸå¤± ===
        å¯ç”¨äº¤å‰æ‰¹æ¬¡æ­£äº¤çº¦æŸï¼Œè®©ç‰¹å¾ç©ºé—´æ›´å½»åº•åˆ†ç¦»
        """
        if id_embeds is None or cloth_embeds is None:
            return torch.tensor(0.0, device=self._get_device())
        
        # ä½¿ç”¨å¢å¼ºç‰ˆæ­£äº¤æŸå¤±
        ortho_loss = self.enhanced_orthogonal(
            id_embeds, cloth_embeds, cross_batch=True
        )
        
        # è°ƒè¯•ä¿¡æ¯
        if self.logger and hasattr(self, '_log_counter_ortho'):
            self._log_counter_ortho = getattr(self, '_log_counter_ortho', 0) + 1
            if self._log_counter_ortho % 200 == 0:
                id_norm = F.normalize(id_embeds, dim=-1, eps=1e-8)
                cloth_norm = F.normalize(cloth_embeds, dim=-1, eps=1e-8)
                cosine_sim = (id_norm * cloth_norm).sum(dim=-1)
                self.logger.debug_logger.debug(
                    f"Enhanced Orthogonal: cosine_sim mean={cosine_sim.mean().item():.4f}, "
                    f"std={cosine_sim.std().item():.4f}, ortho_loss={ortho_loss.item():.6f}"
                )
        
        return ortho_loss
    
    def triplet_loss(self, embeds, pids, margin=0.3):
        """[æ–¹æ¡ˆ C] ID ä¸€è‡´æ€§æŸå¤±ï¼šç¡®ä¿åŒä¸€ ID åœ¨ä¸åŒè¡£æœä¸‹çš„ç‰¹å¾ä¸€è‡´æ€§"""
        if embeds is None or pids is None:
            return torch.tensor(0.0, device=self._get_device())
            
        n = embeds.size(0)
        # è®¡ç®—æ¬§æ°è·ç¦»çŸ©é˜µ
        dist = torch.pow(embeds, 2).sum(dim=1, keepdim=True).expand(n, n)
        dist = dist + dist.t()
        dist.addmm_(embeds, embeds.t(), beta=1, alpha=-2)
        dist = dist.clamp(min=1e-12).sqrt()

        # Hard Mining Mask
        mask = pids.expand(n, n).eq(pids.expand(n, n).t())
        
        # dist_ap: æ¯ä¸ªanchorå¯¹åº”çš„æœ€è¿œæ­£æ ·æœ¬è·ç¦»
        dist_ap, _ = torch.max(dist * mask.float(), dim=1)
        # dist_an: æ¯ä¸ªanchorå¯¹åº”çš„æœ€è¿‘è´Ÿæ ·æœ¬è·ç¦» (maskä¸º0çš„åœ°æ–¹åŠ ä¸ªå¤§æ•°1e6)
        dist_an, _ = torch.min(dist * (1. - mask.float()) + 1e6 * mask.float(), dim=1)

        loss = F.relu(dist_ap - dist_an + margin).mean()
        return loss

    def anti_collapse_loss(self, cloth_embeds, target_norm=8.0, margin_ratio=0.8):
        """
        [ä¼˜åŒ–ç‰ˆ] é˜²åç¼©æ­£åˆ™ï¼šç¡®ä¿è¡£æœç‰¹å¾å­˜åœ¨ï¼Œæ‰“ç ´é›¶å’Œåšå¼ˆ
        
        ä¿®å¤ï¼š
        1. ä½¿ç”¨è‡ªé€‚åº”marginï¼ˆåŸå›ºå®šmargin=1.0è¿œå°äºå®é™…norm=8.0ï¼‰
        2. æ·»åŠ æ–¹å·®æ­£åˆ™ï¼Œé˜²æ­¢ç»´åº¦åç¼©
        
        Args:
            cloth_embeds: è¡£æœç‰¹å¾ [B, D]
            target_norm: ç›®æ ‡èŒƒæ•°ï¼ˆé»˜è®¤8.0ï¼Œä¸å®é™…ç‰¹å¾normåŒ¹é…ï¼‰
            margin_ratio: marginæ¯”ä¾‹ï¼ˆ0.8è¡¨ç¤ºå®¹å¿20%çš„èŒƒæ•°ä¸‹é™ï¼‰
        """
        if cloth_embeds is None:
            return torch.tensor(0.0, device=self._get_device())
        
        # è‡ªé€‚åº”marginï¼šæœŸæœ›normçš„80%
        adaptive_margin = target_norm * margin_ratio  # 8.0 * 0.8 = 6.4
        
        # è®¡ç®— L2 èŒƒæ•°
        norms = torch.norm(cloth_embeds, p=2, dim=-1)  # [B]
        # æƒ©ç½šæ¨¡é•¿è¿‡å°çš„å‘é‡
        norm_loss = F.relu(adaptive_margin - norms).mean()
        
        # ã€æ–°å¢ã€‘æ–¹å·®æ­£åˆ™ï¼šé˜²æ­¢ç‰¹å¾åç¼©åˆ°å°‘æ•°ç»´åº¦
        # è®¡ç®—æ¯ä¸ªç»´åº¦çš„æ ‡å‡†å·®
        feature_std = cloth_embeds.std(dim=0)  # [D]
        # æƒ©ç½šæ ‡å‡†å·®è¿‡å°çš„ç»´åº¦ï¼ˆè¯´æ˜è¯¥ç»´åº¦ä¿¡æ¯é‡ä½ï¼‰
        std_threshold = 0.01  # æœ€å°æ ‡å‡†å·®é˜ˆå€¼
        collapse_loss = F.relu(std_threshold - feature_std).mean()
        
        # ç»„åˆä¸¤ç§æŸå¤±
        total_loss = norm_loss + 0.5 * collapse_loss
        
        return total_loss

    def forward(self, image_embeds, id_text_embeds, fused_embeds, id_logits, id_embeds,
                cloth_embeds, cloth_text_embeds, cloth_image_embeds, pids, 
                is_matched=None, epoch=None, gate=None,
                id_seq_features=None, cloth_seq_features=None, saliency_score=None,
                id_cls_features=None, original_feat=None, freq_info=None):
        """
        å‰å‘ä¼ æ’­ï¼šè®¡ç®—æ‰€æœ‰æŸå¤±ï¼ˆFSHDç‰ˆæœ¬ï¼‰
        
        æ–°å¢å‚æ•°ï¼š
            original_feat: è§£è€¦å‰çš„åŸå§‹ç‰¹å¾ï¼Œç”¨äºé‡æ„ç›‘ç£
            freq_info: é¢‘åŸŸä¿¡æ¯å­—å…¸ï¼ˆåŒ…å«low_freqå’Œhigh_freqï¼‰
        """
        losses = {}
        
        # === P1: åŠ¨æ€æƒé‡æ›´æ–° ===
        if epoch is not None:
            self.update_epoch(epoch)
        
        # === æ ¸å¿ƒæŸå¤±è®¡ç®— ===
        # 1. InfoNCEæŸå¤±
        losses['info_nce'] = self.info_nce_loss(image_embeds, id_text_embeds, fused_embeds) \
            if image_embeds is not None and id_text_embeds is not None \
            else torch.tensor(0.0, device=self._get_device())
        
        # 2. åˆ†ç±»æŸå¤±
        losses['cls'] = self.id_classification_loss(id_logits, pids) \
            if id_logits is not None and pids is not None \
            else torch.tensor(0.0, device=self._get_device())
        
        # 3. æœè£…è¯­ä¹‰æŸå¤±
        losses['cloth_semantic'] = self.cloth_semantic_loss_v2(
            cloth_image_embeds, cloth_text_embeds, id_embeds
        )
        
        # 4. æ­£äº¤çº¦æŸæŸå¤±ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆï¼‰
        losses['orthogonal'] = self.orthogonal_loss_v2(id_embeds, cloth_embeds)
        
        # 5. ID ä¸€è‡´æ€§ Triplet
        losses['id_triplet'] = self.triplet_loss(id_embeds, pids)
        
        # 6. é˜²åç¼©æ­£åˆ™ï¼ˆä¼˜åŒ–ç‰ˆ - ä½¿ç”¨è‡ªé€‚åº”marginï¼‰
        if id_embeds is not None:
            id_collapse_loss = self.anti_collapse_loss(id_embeds)
        else:
            id_collapse_loss = torch.tensor(0.0, device=self._get_device())
        
        if cloth_embeds is not None:
            cloth_collapse_loss = self.anti_collapse_loss(cloth_embeds)
        else:
            cloth_collapse_loss = torch.tensor(0.0, device=self._get_device())
        
        losses['anti_collapse'] = (id_collapse_loss + cloth_collapse_loss) / 2
        
        # 7. é—¨æ§è‡ªé€‚åº”
        losses['gate_adaptive'] = self.gate_adaptive_loss_v2(
            gate, id_embeds, cloth_embeds, pids
        )
        
        # 8. å¯¹ç§°é‡æ„æŸå¤±
        if original_feat is not None and id_embeds is not None and cloth_embeds is not None:
            losses['reconstruction'] = self.symmetric_reconstruction(
                id_embeds, cloth_embeds, original_feat
            )
        else:
            losses['reconstruction'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        # 9. CLIPè¯­ä¹‰å¯¹é½æŸå¤±
        if self.semantic_guidance_module is not None and \
           id_embeds is not None and cloth_embeds is not None:
            losses['semantic_alignment'] = self.semantic_guidance_module(
                id_embeds, cloth_embeds, use_cross_separation=False
            )
        else:
            losses['semantic_alignment'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        # 10. ã€æ–°å¢ã€‘é¢‘åŸŸä¸€è‡´æ€§æŸå¤±
        if freq_info is not None and 'low_freq' in freq_info and 'high_freq' in freq_info:
            # ä»freq_infoæå–é¢‘åŸŸç‰¹å¾ï¼ˆéœ€è¦æ± åŒ–ä¸ºå…¨å±€ç‰¹å¾ï¼‰
            low_freq_seq = freq_info['low_freq']  # [B, N, D]
            high_freq_seq = freq_info['high_freq']
            
            # å…¨å±€å¹³å‡æ± åŒ–
            low_freq_global = low_freq_seq.mean(dim=1)  # [B, D]
            high_freq_global = high_freq_seq.mean(dim=1)
            
            if id_embeds is not None and cloth_embeds is not None:
                losses['freq_consistency'] = self.frequency_consistency(
                    id_embeds, cloth_embeds, low_freq_global, high_freq_global
                )
            else:
                losses['freq_consistency'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        else:
            losses['freq_consistency'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        # 11. ã€æ–°å¢ã€‘é¢‘åŸŸåˆ†ç¦»æŸå¤±ï¼ˆå¯é€‰ï¼Œé»˜è®¤æƒé‡è¾ƒå°ï¼‰
        if freq_info is not None and 'low_freq' in freq_info and 'high_freq' in freq_info:
            low_freq_global = freq_info['low_freq'].mean(dim=1)
            high_freq_global = freq_info['high_freq'].mean(dim=1)
            
            if id_embeds is not None and cloth_embeds is not None:
                losses['freq_separation'] = self.frequency_separation(
                    id_embeds, cloth_embeds, low_freq_global, high_freq_global
                )
            else:
                losses['freq_separation'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        else:
            losses['freq_separation'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)
        
        # === NaN/Infæ£€æŸ¥ ===
        for key, value in losses.items():
            if isinstance(value, torch.Tensor):
                if torch.isnan(value).any() or torch.isinf(value).any():
                    if self.logger:
                        self.debug_logger.warning(f"âš ï¸  WARNING: Loss '{key}' contains NaN/Inf! Resetting to 0.0.")
                    losses[key] = torch.tensor(0.0, device=value.device, requires_grad=True)
        
        # === åŠ æƒæ±‚å’Œ ===
        total_loss = sum(self.weights.get(k, 0) * losses[k] 
                        for k in losses.keys() if k != 'total')
        
        # æœ€ç»ˆæ£€æŸ¥
        if torch.isnan(total_loss).any() or torch.isinf(total_loss).any():
            total_loss = torch.tensor(0.0, device=total_loss.device, requires_grad=True)
        
        losses['total'] = total_loss
        
        return losses