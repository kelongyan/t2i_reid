import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from utils.loss_logger import LossLogger


class SymmetricReconstructionLoss(nn.Module):
    """
    ç®€åŒ–çš„é‡æ„æŸå¤± - ä»…å…³æ³¨ä¿¡æ¯å®Œæ•´æ€§

    æ ¸å¿ƒæ€æƒ³ï¼šF_input â‰ˆ F_id + F_attr
    ç¡®ä¿è§£è€¦åçš„ä¸¤ä¸ªç‰¹å¾èƒ½å¤Ÿé‡å»ºåŸå§‹è¾“å…¥ï¼Œé˜²æ­¢ä¿¡æ¯ä¸¢å¤±

    é‡æ„è¯´æ˜ï¼š
    - ç§»é™¤å¤æ‚çš„Cosineã€Diversityã€EnergyæŸå¤±
    - ä»…ä¿ç•™MSEæŸå¤±ï¼Œè®©æ¨¡å‹è‡ªç„¶å­¦ä¹ é‡æ„
    - ä¸orthogonal_lossé…åˆï¼Œé¿å…ç‰¹å¾é‡å 
    """
    def __init__(self):
        super().__init__()
        self.mse_loss = nn.MSELoss()

    def forward(self, id_feat, attr_feat, original_feat):
        """
        Args:
            id_feat: IDç‰¹å¾ [B, dim]
            attr_feat: Attrç‰¹å¾ [B, dim]
            original_feat: åŸå§‹ç‰¹å¾ï¼ˆè§£è€¦å‰çš„å…¨å±€ç‰¹å¾ï¼‰[B, dim]

        Returns:
            loss: é‡æ„æŸå¤±ï¼ˆMSEï¼‰
        """
        # ç®€å•åŠ æ³•é‡å»º
        reconstructed = id_feat + attr_feat  # [B, dim]

        # ä»…ä½¿ç”¨MSEæŸå¤±
        mse_loss = self.mse_loss(reconstructed, original_feat)

        return mse_loss


class EnhancedOrthogonalLoss(nn.Module):
    """
    å¢å¼ºæ­£äº¤æŸå¤± (Enhanced Orthogonal Loss)

    æ”¹è¿›ï¼šå¢åŠ äº¤å‰æ‰¹æ¬¡çº¦æŸï¼Œè®©ä¸åŒæ ·æœ¬çš„IDå’ŒAttrç‰¹å¾ç©ºé—´ä¹Ÿè¶‹å‘æ­£äº¤
    """
    def __init__(self):
        super().__init__()

    def forward(self, id_embeds, attr_embeds, cross_batch=True):
        """
        Args:
            id_embeds: IDç‰¹å¾ [B, dim]
            attr_embeds: Attrç‰¹å¾ [B, dim]
            cross_batch: æ˜¯å¦å¯ç”¨äº¤å‰æ‰¹æ¬¡æ­£äº¤çº¦æŸ

        Returns:
            loss: æ­£äº¤æŸå¤±
        """
        # å½’ä¸€åŒ–
        id_norm = F.normalize(id_embeds, dim=-1, eps=1e-8)     # [B, dim]
        attr_norm = F.normalize(attr_embeds, dim=-1, eps=1e-8) # [B, dim]

        # === æ‰¹æ¬¡å†…æ­£äº¤çº¦æŸï¼ˆæ ·æœ¬è‡ªå·±çš„IDå’ŒAttræ­£äº¤ï¼‰===
        # ä½™å¼¦ç›¸ä¼¼åº¦ï¼šåº”è¯¥æ¥è¿‘0
        intra_cosine = (id_norm * attr_norm).sum(dim=-1)  # [B]
        intra_cosine = torch.clamp(intra_cosine, min=-1.0, max=1.0)
        intra_loss = intra_cosine.pow(2).mean()

        # === äº¤å‰æ‰¹æ¬¡æ­£äº¤çº¦æŸï¼ˆæ‰€æœ‰ID vs æ‰€æœ‰Attrï¼‰===
        if cross_batch and id_embeds.size(0) > 1:
            # è®¡ç®—å…¨å±€ç›¸ä¼¼åº¦çŸ©é˜µ [B, B]
            cross_sim = torch.matmul(id_norm, attr_norm.t())
            # æœ€å°åŒ–æ‰€æœ‰å…ƒç´ çš„å¹³æ–¹å’Œï¼ˆè®©æ•´ä¸ªçŸ©é˜µè¶‹å‘0ï¼‰
            cross_loss = cross_sim.pow(2).mean()

            return intra_loss + 0.5 * cross_loss
        else:
            return intra_loss


class Loss(nn.Module):
    """
    === FSHDæŸå¤±å‡½æ•°æ¨¡å— (é‡æ„ç‰ˆ - Phase 2) ===

    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. ç®€åŒ–æŸå¤±ä½“ç³»ï¼š11ä¸ªæŸå¤± â†’ 5ä¸ªæ ¸å¿ƒæŸå¤±
    2. ä¿®å¤å…³é”®bugï¼šanti_collapseçš„target_normè‡ªé€‚åº”æ£€æµ‹
    3. ä¼˜åŒ–æƒé‡é…ç½®ï¼šæå‡CLSå’Œå…³é”®è¾…åŠ©æŸå¤±çš„æƒé‡
    4. ç§»é™¤å¤±æ•ˆ/å†²çªçš„æŸå¤±ï¼šfreq_consistencyã€freq_separationã€gate_adaptiveã€semantic_alignment

    ä¿ç•™çš„5ä¸ªæ ¸å¿ƒæŸå¤±ï¼š
    - InfoNCE: ä¸»å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆå›¾æ–‡åŒ¹é…ï¼‰
    - Orthogonal: ID-Attræ­£äº¤çº¦æŸï¼ˆè§£è€¦æ ¸å¿ƒï¼‰
    - AntiCollapse: é˜²æ­¢ç‰¹å¾åç¼©ï¼ˆèŒƒæ•°+æ–¹å·®çº¦æŸï¼‰
    - IdTriplet: åŒIDä¸€è‡´æ€§ï¼ˆæœè£…å˜åŒ–ä¸‹çš„èº«ä»½ä¸å˜æ€§ï¼‰
    - ClothSemantic: æœè£…è¯­ä¹‰å¯¹é½ï¼ˆè¾…åŠ©ä»»åŠ¡ï¼‰

    åˆ é™¤çš„6ä¸ªæŸå¤±ï¼š
    - freq_consistency: ä¸orthogonalåŠŸèƒ½é‡å 
    - freq_separation: ä¸orthogonalåŠŸèƒ½é‡å 
    - reconstruction: ç®€åŒ–ä¸ºä»…MSEï¼Œä½œä¸ºå¯é€‰ç›‘ç£
    - gate_adaptive: è¿‡äºå¤æ‚ï¼Œæ•ˆæœæœ‰é™
    - semantic_alignment: ä¸cloth_semanticé‡å 
    - cls: å¯é€‰ï¼Œå»ºè®®é™ä½æƒé‡æˆ–åˆ é™¤
    """

    def __init__(self, temperature=0.1, weights=None, num_classes=None, logger=None):
        super().__init__()
        self.temperature = temperature
        self.num_classes = num_classes
        self.logger = logger

        # ğŸ”¥ å¢å¼ºLabel Smoothingï¼Œé™ä½åˆ†ç±»æŸå¤±çš„åˆå§‹å€¼å’Œæ•æ„Ÿåº¦
        # 0.1 â†’ 0.2: æ›´å¼ºçš„æ­£åˆ™åŒ–ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=0.2)

        # === æ ¸å¿ƒæŸå¤±æ¨¡å—ï¼ˆç®€åŒ–ç‰ˆï¼‰===
        self._reconstruction_loss = SymmetricReconstructionLoss()
        self._orthogonal_loss_module = EnhancedOrthogonalLoss()

        # === åˆå§‹åŒ–LossLogger ===
        self.loss_logger = LossLogger(logger.debug_logger) if logger else None

        # === ğŸ”¥ ç´§æ€¥ä¿®å¤ç‰ˆæƒé‡é…ç½® ===
        # ç­–ç•¥ï¼šé™ä½CLSå’Œcloth_semanticä¸»å¯¼ï¼Œå¢å¼ºå¯¹æ¯”å­¦ä¹ å’Œè§£è€¦
        self.weights = weights if weights is not None else {
            # === æ ¸å¿ƒä»»åŠ¡æŸå¤± ===
            'info_nce': 1.0,              # å¯¹æ¯”å­¦ä¹  - ä¸»ä»»åŠ¡
            'cls': 0.15,                  # ğŸ”¥ å¤§å¹…é™ä½ (0.3 â†’ 0.15)ï¼Œé¿å…è¿‡æ‹Ÿåˆ
            'cloth_semantic': 0.2,        # ğŸ”¥ å¤§å¹…é™ä½ (0.5 â†’ 0.2)ï¼Œå‡å°‘ä¸orthogonalå†²çª

            # === è§£è€¦ä¸çº¦æŸæŸå¤± ===
            'orthogonal': 0.3,            # ğŸ”¥ æå‡ (0.15 â†’ 0.3)ï¼Œå¼ºåŒ–è§£è€¦
            'id_triplet': 0.8,            # IDä¸€è‡´æ€§ï¼ˆä¿æŒï¼‰
            'anti_collapse': 1.5,         # ğŸ”¥ æå‡ (1.0 â†’ 1.5)ï¼Œä¿®å¤åæ¿€æ´»

            # === è¾…åŠ©ç›‘ç£æŸå¤± ===
            'reconstruction': 0.2,        # ğŸ”¥ é™ä½ (0.3 â†’ 0.2)

            # === å·²åˆ é™¤çš„æŸå¤±ï¼ˆä¿æŒæƒé‡ä¸º0ï¼Œå…¼å®¹æ€§ï¼‰===
            'gate_adaptive': 0.0,         # å·²åˆ é™¤ï¼ˆè¿‡äºå¤æ‚ï¼‰
            'semantic_alignment': 0.0,    # å·²åˆ é™¤ï¼ˆä¸cloth_semanticé‡å ï¼‰
            'freq_consistency': 0.0,      # å·²åˆ é™¤ï¼ˆä¸orthogonalé‡å ï¼‰
            'freq_separation': 0.0,       # å·²åˆ é™¤ï¼ˆä¸orthogonalé‡å ï¼‰
        }

        # åŠ¨æ€æƒé‡è°ƒæ•´å‚æ•°
        self.current_epoch = 0
        self.enable_dynamic_weights = True

        # è¯­ä¹‰å¼•å¯¼æ¨¡å—ï¼ˆå¤–éƒ¨ä¼ å…¥ï¼Œå¯é€‰ï¼‰
        self.semantic_guidance_module = None

        # æ³¨å†Œdummyå‚æ•°ç”¨äºè·å–è®¾å¤‡
        self.register_buffer('_dummy', torch.zeros(1))

        # è°ƒè¯•è®¡æ•°å™¨
        if logger:
            self.debug_logger = logger.debug_logger
            self._log_counter_ortho = 0
            self._log_counter_triplet = 0
            self._log_counter_anti_collapse = 0
            self._log_counter_info_nce = 0
            self._batch_counter = 0

    def set_semantic_guidance(self, semantic_guidance_module):
        """
        è®¾ç½®è¯­ä¹‰å¼•å¯¼æ¨¡å—ï¼ˆå·²åºŸå¼ƒï¼Œä¿æŒæ¥å£å…¼å®¹ï¼‰
        """
        self.semantic_guidance_module = semantic_guidance_module
        if self.logger:
            self.debug_logger.info("âš ï¸  Semantic guidance module attached (DEPRECATED - will not be used)")

    def _get_device(self):
        """å®‰å…¨è·å–è®¾å¤‡"""
        return self._dummy.device

    def update_epoch(self, epoch):
        """
        === ğŸ”¥ ç´§æ€¥ä¿®å¤ç‰ˆï¼šæ¿€è¿›çš„æƒé‡è°ƒæ•´ç­–ç•¥ ===

        ç­–ç•¥ï¼š
        - Stage 1 (Epoch 1-10): å¿«é€Ÿå»ºç«‹åŸºç¡€ç‰¹å¾ï¼Œé™ä½CLSä¸»å¯¼
        - Stage 2 (Epoch 11-30): å¼ºåŒ–è§£è€¦ï¼Œé€æ­¥æ¿€æ´»cloth_semantic
        - Stage 3 (Epoch 31+): å¯¹æ¯”å­¦ä¹ ä¸»å¯¼ï¼Œåˆ†ç±»æœ€å°åŒ–
        """
        self.current_epoch = epoch

        if not self.enable_dynamic_weights:
            return

        # === ğŸ”¥ æ¿€è¿›çš„ä¸‰é˜¶æ®µæƒé‡è°ƒæ•´ ===
        if epoch <= 10:
            # Stage 1: åŸºç¡€å­¦ä¹  - é™ä½CLSï¼Œå…³é—­cloth_semantic
            self.weights['info_nce'] = 1.0
            self.weights['cls'] = 0.2          # ğŸ”¥ é™ä½ (åŸ0.5)
            self.weights['cloth_semantic'] = 0.0  # ğŸ”¥ å®Œå…¨ç¦ç”¨ï¼Œé¿å…å†²çª
            self.weights['orthogonal'] = 0.3   # ğŸ”¥ æå‡ï¼Œä¼˜å…ˆå»ºç«‹æ­£äº¤
            self.weights['anti_collapse'] = 1.5
            self.weights['reconstruction'] = 0.3
        elif epoch <= 30:
            # Stage 2: ç²¾ç»†è§£è€¦ - é€æ­¥æ¿€æ´»cloth_semantic
            self.weights['info_nce'] = 1.2     # ğŸ”¥ å¢å¼ºä¸»ä»»åŠ¡
            self.weights['cls'] = 0.15         # ğŸ”¥ ç»§ç»­é™ä½
            # ğŸ”¥ çº¿æ€§å¢é•¿ï¼šepoch 11â†’0.05, epoch 20â†’0.15, epoch 30â†’0.2
            cloth_weight = 0.05 + (epoch - 10) * 0.0075
            self.weights['cloth_semantic'] = min(cloth_weight, 0.2)
            self.weights['orthogonal'] = 0.4   # ğŸ”¥ ç»§ç»­å¢å¼º
            self.weights['anti_collapse'] = 2.0
            self.weights['reconstruction'] = 0.2
        else:
            # Stage 3: å¯¹æ¯”å­¦ä¹ ä¸»å¯¼
            self.weights['info_nce'] = 1.5     # ğŸ”¥ æœ€å¤§åŒ–
            self.weights['cls'] = 0.05         # ğŸ”¥ æœ€å°åŒ–
            self.weights['cloth_semantic'] = 0.15  # ğŸ”¥ ä¿æŒä½æƒé‡
            self.weights['orthogonal'] = 0.3
            self.weights['anti_collapse'] = 2.0
            self.weights['reconstruction'] = 0.15

        # è®°å½•æƒé‡å˜åŒ–ï¼ˆä»…å…³é”®epochï¼‰
        if self.logger and epoch in [1, 11, 31]:
            self.debug_logger.info(f"ğŸ”¥ Loss weights updated at epoch {epoch}:")
            for k, v in self.weights.items():
                if v > 0:  # åªæ˜¾ç¤ºæ¿€æ´»çš„æŸå¤±
                    self.debug_logger.info(f"   - {k}: {v:.4f}")

    def anti_collapse_loss(self, cloth_embeds, target_norm=None, margin_ratio=0.8):
        """
        [ä¿®å¤ç‰ˆ] é˜²åç¼©æ­£åˆ™ï¼šç¡®ä¿ç‰¹å¾å­˜åœ¨ï¼Œé˜²æ­¢é›¶å’Œåšå¼ˆ

        æ ¸å¿ƒä¿®å¤ï¼š
        1. ä½¿ç”¨EMAè¿½è¸ªç›®æ ‡èŒƒæ•°ï¼ˆé¿å…è‡ªé€‚åº”å¯¼è‡´loss=0çš„BUGï¼‰
        2. å›ºå®šmarginç­–ç•¥ï¼Œç¡®ä¿æŸå¤±å§‹ç»ˆæœ‰æ•ˆ
        3. æ·»åŠ æ–¹å·®æ­£åˆ™ï¼Œé˜²æ­¢ç»´åº¦åç¼©

        Args:
            cloth_embeds: è¡£æœ/IDç‰¹å¾ [B, D]
            target_norm: ç›®æ ‡èŒƒæ•°ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨EMAè¿½è¸ªï¼‰
            margin_ratio: marginæ¯”ä¾‹ï¼ˆ0.8è¡¨ç¤ºå®¹å¿20%çš„èŒƒæ•°ä¸‹é™ï¼‰
        """
        if cloth_embeds is None:
            return torch.tensor(0.0, device=self._get_device())

        # ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨EMAè¿½è¸ªç›®æ ‡èŒƒæ•°ï¼Œé¿å…è‡ªé€‚åº”BUG
        current_mean_norm = torch.norm(cloth_embeds, p=2, dim=-1).mean().item()
        
        if target_norm is None:
            # åˆå§‹åŒ–æˆ–æ›´æ–°EMA
            if not hasattr(self, '_target_norm_ema'):
                # é¦–æ¬¡åˆå§‹åŒ–ï¼šå¦‚æœå½“å‰èŒƒæ•°åˆç†åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ç”¨é»˜è®¤å€¼
                if current_mean_norm > 1.0:
                    self._target_norm_ema = current_mean_norm * 1.2  # åˆå§‹ç›®æ ‡ç•¥é«˜äºå½“å‰
                else:
                    self._target_norm_ema = 8.0  # é»˜è®¤ç›®æ ‡
            else:
                # EMAæ›´æ–°ï¼š90%æ—§å€¼ + 10%æ–°å€¼
                self._target_norm_ema = 0.9 * self._target_norm_ema + 0.1 * current_mean_norm
            
            # ç›®æ ‡èŒƒæ•°ï¼šEMAçš„1.2å€ï¼ˆé¼“åŠ±ç‰¹å¾é€‚åº¦å¢é•¿ï¼‰
            target_norm = self._target_norm_ema * 1.2
        
        # ã€å…³é”®ä¿®å¤ã€‘marginå¿…é¡»å°äºtarget_normï¼Œç¡®ä¿æŸå¤±æœ‰æ•ˆ
        # ä½¿ç”¨target_normçš„80%ä½œä¸ºä¸‹ç•Œï¼Œä½äºæ­¤å€¼å°†å—åˆ°æƒ©ç½š
        adaptive_margin = target_norm * margin_ratio

        # è®¡ç®—L2èŒƒæ•°
        norms = torch.norm(cloth_embeds, p=2, dim=-1)  # [B]
        # æƒ©ç½šæ¨¡é•¿è¿‡å°çš„å‘é‡
        norm_loss = F.relu(adaptive_margin - norms).mean()

        # ã€ä¿®å¤ã€‘æ–¹å·®æ­£åˆ™ï¼šé˜²æ­¢ç‰¹å¾åç¼©åˆ°å°‘æ•°ç»´åº¦
        # è®¡ç®—æ¯ä¸ªç»´åº¦çš„æ ‡å‡†å·®
        feature_std = cloth_embeds.std(dim=0)  # [D]
        # æƒ©ç½šæ ‡å‡†å·®è¿‡å°çš„ç»´åº¦ï¼ˆè¯´æ˜è¯¥ç»´åº¦ä¿¡æ¯é‡ä½ï¼‰
        std_threshold = 0.01  # æœ€å°æ ‡å‡†å·®é˜ˆå€¼
        collapse_loss = F.relu(std_threshold - feature_std).mean()

        # ç»„åˆä¸¤ç§æŸå¤±
        total_loss = norm_loss + 0.5 * collapse_loss

        # è°ƒè¯•ä¿¡æ¯
        if self.logger and self.loss_logger:
            if self.loss_logger.should_log('anti_collapse'):
                self.loss_logger.log_anti_collapse_stats(
                    cloth_embeds, target_norm, margin_ratio, total_loss
                )

        return total_loss

    def info_nce_loss(self, image_embeds, text_embeds, fused_embeds=None):
        """
        InfoNCEå¯¹æ¯”å­¦ä¹ æŸå¤±

        ä¿®å¤ï¼šæ”¯æŒä½¿ç”¨fused_embedså‚ä¸å¯¹æ¯”å­¦ä¹ 
        è®©Fusionæ¨¡å—çœŸæ­£å½±å“ä¸»ä»»åŠ¡ï¼Œé¿å…æ¢¯åº¦æ­»äº¡
        """
        if image_embeds is None or text_embeds is None:
            return torch.tensor(0.0, device=self._get_device())

        # ä¼˜å…ˆä½¿ç”¨fused_embedsï¼ˆèåˆåçš„ç‰¹å¾ï¼‰
        # å¦‚æœæ²¡æœ‰fusionæˆ–fusionæœªæ¿€æ´»ï¼Œåˆ™ä½¿ç”¨image_embeds
        visual_embeds = fused_embeds if fused_embeds is not None else image_embeds

        bsz = visual_embeds.size(0)
        visual_embeds = F.normalize(visual_embeds, dim=-1, eps=1e-8)
        text_embeds = F.normalize(text_embeds, dim=-1, eps=1e-8)

        sim = torch.matmul(visual_embeds, text_embeds.t()) / self.temperature
        sim = torch.clamp(sim, min=-50, max=50)

        labels = torch.arange(bsz, device=sim.device, dtype=torch.long)
        loss_i2t = self.ce_loss(sim, labels)
        loss_t2i = self.ce_loss(sim.t(), labels)

        total_loss = (loss_i2t + loss_t2i) / 2

        # è°ƒè¯•ä¿¡æ¯
        if self.logger and self.loss_logger:
            if self.loss_logger.should_log('info_nce'):
                self.loss_logger.log_info_nce_stats(
                    visual_embeds, text_embeds, total_loss, self.temperature
                )

        return total_loss

    def id_classification_loss(self, id_logits, pids):
        """
        èº«ä»½åˆ†ç±»æŸå¤±

        === ä¿®å¤æ–¹æ¡ˆ ===
        1. ç§»é™¤æ¸©åº¦ç¼©æ”¾ - è®©åˆ†ç±»å™¨æ­£å¸¸å­¦ä¹ 
        2. ä¿ç•™logitsè£å‰ªé˜²æ­¢æ•°å€¼çˆ†ç‚¸
        3. é€šè¿‡åŠ¨æ€æƒé‡æ§åˆ¶å­¦ä¹ é€Ÿåº¦ï¼Œè€Œéæ¸©åº¦ç¼©æ”¾
        """
        if id_logits is None or pids is None:
            return torch.tensor(0.0, device=self._get_device())

        # è£å‰ªé˜²æ­¢æ•°å€¼çˆ†ç‚¸
        id_logits_clipped = torch.clamp(id_logits, min=-50, max=50)

        # ç›´æ¥è®¡ç®—CEæŸå¤±ï¼Œä¸ä½¿ç”¨æ¸©åº¦ç¼©æ”¾
        ce_loss = self.ce_loss(id_logits_clipped, pids)

        # è°ƒè¯•ä¿¡æ¯
        if self.logger and self.loss_logger:
            if self.loss_logger.should_log('cls'):
                self.loss_logger.log_cls_stats(
                    id_logits_clipped, pids, ce_loss
                )

        return ce_loss

    def cloth_semantic_loss(self, cloth_image_embeds, cloth_text_embeds):
        """
        === ä¿®å¤æ–¹æ¡ˆï¼šç®€åŒ–çš„cloth_semanticæŸå¤± ===
        ç§»é™¤å»IDæ­£åˆ™ï¼Œè®©æ¨¡å‹ä¸“æ³¨äºæœè£…è¯­ä¹‰å¯¹é½
        """
        if cloth_image_embeds is None or cloth_text_embeds is None:
            return torch.tensor(0.0, device=self._get_device())

        bsz = cloth_image_embeds.size(0)

        # æ ‡å‡†å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆä¸InfoNCEä¸€è‡´ï¼‰
        cloth_image_norm = F.normalize(cloth_image_embeds, dim=-1, eps=1e-8)
        cloth_text_norm = F.normalize(cloth_text_embeds, dim=-1, eps=1e-8)

        sim = torch.matmul(cloth_image_norm, cloth_text_norm.t()) / self.temperature
        sim = torch.clamp(sim, min=-50, max=50)

        labels = torch.arange(bsz, device=sim.device, dtype=torch.long)
        loss_i2t = self.ce_loss(sim, labels)
        loss_t2i = self.ce_loss(sim.t(), labels)

        total_loss = (loss_i2t + loss_t2i) / 2

        # è°ƒè¯•ä¿¡æ¯
        if self.logger and self.loss_logger:
            if self.loss_logger.should_log('cloth_semantic'):
                self.loss_logger.log_cloth_semantic_stats(
                    cloth_image_norm, cloth_text_norm, total_loss, self.temperature
                )

        return total_loss

    def orthogonal_loss(self, id_embeds, cloth_embeds):
        """
        === å¯¹ç§°è§£è€¦æ”¹è¿›ï¼šä½¿ç”¨å¢å¼ºæ­£äº¤æŸå¤± ===
        å¯ç”¨äº¤å‰æ‰¹æ¬¡æ­£äº¤çº¦æŸï¼Œè®©ç‰¹å¾ç©ºé—´æ›´å½»åº•åˆ†ç¦»
        """
        if id_embeds is None or cloth_embeds is None:
            return torch.tensor(0.0, device=self._get_device())

        # ä½¿ç”¨å¢å¼ºç‰ˆæ­£äº¤æŸå¤±
        ortho_loss = self._orthogonal_loss_module(
            id_embeds, cloth_embeds, cross_batch=True
        )

        # è°ƒè¯•ä¿¡æ¯
        if self.logger and self.loss_logger:
            if self.loss_logger.should_log('orthogonal'):
                self.loss_logger.log_orthogonality_stats(
                    id_embeds, cloth_embeds, ortho_loss
                )

        return ortho_loss

    def triplet_loss(self, embeds, pids, margin=0.3):
        """
        ID ä¸€è‡´æ€§æŸå¤±ï¼šç¡®ä¿åŒä¸€ ID åœ¨ä¸åŒè¡£æœä¸‹çš„ç‰¹å¾ä¸€è‡´æ€§
        """
        if embeds is None or pids is None:
            return torch.tensor(0.0, device=self._get_device())

        n = embeds.size(0)
        # è®¡ç®—æ¬§æ°è·ç¦»çŸ©é˜µ
        dist = torch.pow(embeds, 2).sum(dim=1, keepdim=True).expand(n, n)
        dist = dist + dist.t()
        dist.addmm_(embeds, embeds.t(), beta=1, alpha=-2)
        dist = dist.clamp(min=1e-12).sqrt()

        # Hard Mining Mask
        mask = pids.expand(n, n).eq(pids.expand(n, n).t())

        # dist_ap: æ¯ä¸ªanchorå¯¹åº”çš„æœ€è¿œæ­£æ ·æœ¬è·ç¦»
        dist_ap, _ = torch.max(dist * mask.float(), dim=1)
        # dist_an: æ¯ä¸ªanchorå¯¹åº”çš„æœ€è¿‘è´Ÿæ ·æœ¬è·ç¦» (maskä¸º0çš„åœ°æ–¹åŠ ä¸ªå¤§æ•°1e6)
        dist_an, _ = torch.min(dist * (1. - mask.float()) + 1e6 * mask.float(), dim=1)

        loss = F.relu(dist_ap - dist_an + margin).mean()

        # è°ƒè¯•ä¿¡æ¯
        if self.logger and self.loss_logger:
            if self.loss_logger.should_log('id_triplet'):
                self.loss_logger.log_triplet_stats(
                    embeds, pids, loss, margin
                )

        return loss

    def forward(self, image_embeds, id_text_embeds, fused_embeds, id_logits, id_embeds,
                cloth_embeds, cloth_text_embeds, cloth_image_embeds, pids,
                is_matched=None, epoch=None, gate=None,
                id_seq_features=None, cloth_seq_features=None, saliency_score=None,
                id_cls_features=None, original_feat=None, freq_info=None):
        """
        å‰å‘ä¼ æ’­ï¼šè®¡ç®—æ‰€æœ‰æŸå¤±ï¼ˆPhase 2é‡æ„ç‰ˆï¼‰

        æ–°å¢å‚æ•°ï¼š
            original_feat: è§£è€¦å‰çš„åŸå§‹ç‰¹å¾ï¼Œç”¨äºé‡æ„ç›‘ç£ï¼ˆå¯é€‰ï¼‰
            freq_info: é¢‘åŸŸä¿¡æ¯å­—å…¸ï¼ˆå·²åºŸå¼ƒï¼Œä¿æŒæ¥å£å…¼å®¹ï¼‰
        """
        losses = {}

        # === P1: åŠ¨æ€æƒé‡æ›´æ–° ===
        if epoch is not None:
            self.update_epoch(epoch)

        # === æ ¸å¿ƒæŸå¤±è®¡ç®—ï¼ˆç®€åŒ–ç‰ˆ - 5ä¸ªæ ¸å¿ƒæŸå¤±ï¼‰===
        # 1. InfoNCEæŸå¤±ï¼ˆä¸»ä»»åŠ¡ï¼‰
        losses['info_nce'] = self.info_nce_loss(image_embeds, id_text_embeds, fused_embeds) \
            if image_embeds is not None and id_text_embeds is not None \
            else torch.tensor(0.0, device=self._get_device())

        # 2. åˆ†ç±»æŸå¤±ï¼ˆå¯é€‰ï¼Œå»ºè®®é™ä½æƒé‡ï¼‰
        losses['cls'] = self.id_classification_loss(id_logits, pids) \
            if id_logits is not None and pids is not None \
            else torch.tensor(0.0, device=self._get_device())

        # 3. æœè£…è¯­ä¹‰æŸå¤±ï¼ˆè¾…åŠ©ä»»åŠ¡ï¼‰
        losses['cloth_semantic'] = self.cloth_semantic_loss(
            cloth_image_embeds, cloth_text_embeds
        )

        # 4. æ­£äº¤çº¦æŸæŸå¤±ï¼ˆè§£è€¦æ ¸å¿ƒï¼‰
        losses['orthogonal'] = self.orthogonal_loss(id_embeds, cloth_embeds)

        # 5. ID ä¸€è‡´æ€§ Triplet
        losses['id_triplet'] = self.triplet_loss(id_embeds, pids)

        # 6. é˜²åç¼©æ­£åˆ™ï¼ˆä¿®å¤ç‰ˆ - è‡ªåŠ¨æ£€æµ‹target_normï¼‰
        # å¯¹IDå’ŒAttrç‰¹å¾éƒ½åº”ç”¨é˜²åç¼©çº¦æŸ
        id_collapse_loss = self.anti_collapse_loss(id_embeds) if id_embeds is not None \
            else torch.tensor(0.0, device=self._get_device())
        cloth_collapse_loss = self.anti_collapse_loss(cloth_embeds) if cloth_embeds is not None \
            else torch.tensor(0.0, device=self._get_device())

        losses['anti_collapse'] = (id_collapse_loss + cloth_collapse_loss) / 2

        # 7. é‡æ„æŸå¤±ï¼ˆå¯é€‰ - ç®€åŒ–ä¸ºMSEï¼‰
        if original_feat is not None and id_embeds is not None and cloth_embeds is not None:
            losses['reconstruction'] = self._reconstruction_loss(
                id_embeds, cloth_embeds, original_feat
            )

            # è°ƒè¯•ä¿¡æ¯
            if self.logger and self.loss_logger and self.loss_logger.should_log('reconstruction'):
                self.loss_logger.log_reconstruction_stats(
                    id_embeds, cloth_embeds, original_feat, losses['reconstruction']
                )
        else:
            losses['reconstruction'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)

        # === å·²åˆ é™¤çš„æŸå¤±ï¼ˆä¿æŒæ¥å£å…¼å®¹ï¼Œè¿”å›0ï¼‰===
        # gate_adaptive - å·²åˆ é™¤
        losses['gate_adaptive'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)

        # semantic_alignment - å·²åˆ é™¤
        losses['semantic_alignment'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)

        # freq_consistency - å·²åˆ é™¤
        losses['freq_consistency'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)

        # freq_separation - å·²åˆ é™¤
        losses['freq_separation'] = torch.tensor(0.0, device=self._get_device(), requires_grad=True)

        # === NaN/Infæ£€æŸ¥ ===
        for key, value in losses.items():
            if isinstance(value, torch.Tensor):
                if torch.isnan(value).any() or torch.isinf(value).any():
                    if self.logger:
                        self.debug_logger.warning(f"âš ï¸  WARNING: Loss '{key}' contains NaN/Inf! Resetting to 0.0.")
                    losses[key] = torch.tensor(0.0, device=value.device, requires_grad=True)

        # === åŠ æƒæ±‚å’Œ ===
        total_loss = sum(self.weights.get(k, 0) * losses[k]
                        for k in losses.keys() if k != 'total')

        # æœ€ç»ˆæ£€æŸ¥
        if torch.isnan(total_loss).any() or torch.isinf(total_loss).any():
            total_loss = torch.tensor(0.0, device=total_loss.device, requires_grad=True)

        losses['total'] = total_loss

        # è®°å½•åŠ æƒæŸå¤±æ‘˜è¦ï¼ˆæ¯100ä¸ªbatchï¼‰
        if self.logger and self.loss_logger:
            self._batch_counter += 1
            if self._batch_counter % 100 == 0:
                self.loss_logger.log_weighted_loss_summary(losses, self.weights)

        return losses
